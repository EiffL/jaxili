
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>jaxili.inference.nle &#8212; JaxILI 0.1.3 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=8f2a1f02" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=eba8b062" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../../../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../../../_static/documentation_options.js?v=b617ff6d"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/jaxili/inference/nle';</script>
    <link rel="author" title="About these documents" href="../../../about.html" />
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">JaxILI 0.1.3 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../manual/index.html">Software manual</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../manual/installation.html">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../manual/first_steps.html">First steps</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../manual/release_notes.html">Release notes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../manual/get_in_touch.html">Get in touch</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../examples/index.html">Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/getting_started.html">Getting started with <code class="docutils literal notranslate"><span class="pre">JaxILI</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/nle_quickstart.html">Neural Likelihood Estimation Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../examples/training_conditional_maf.html">Training a Conditional MAF</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../user_guide/index.html">User guide</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../user_guide/how_jaxili_work.html">How <code class="docutils literal notranslate"><span class="pre">JaxILI</span></code> works</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../index_reference.html">Reference</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../jaxili.inference.html">jaxili.inference package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../jaxili.inference.nle.html">jaxili.inference.nle module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../jaxili.inference.npe.html">jaxili.inference.npe module</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../jaxili.loss.html">jaxili.loss module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../jaxili.model.html">jaxili.model module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../jaxili.posterior.html">jaxili.posterior package</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../jaxili.posterior.base_posterior.html">jaxili.posterior.base_posterior module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../jaxili.posterior.direct_posterior.html">jaxili.posterior.direct_posterior module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../jaxili.posterior.mcmc_posterior.html">jaxili.posterior.mcmc_posterior module</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../jaxili.train.html">jaxili.train module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../jaxili.utils.html">jaxili.utils module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../jaxili.validation.html">jaxili.validation module</a></li>
</ul>
</details></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for jaxili.inference.nle</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">NLE.</span>

<span class="sd">This modules provides a Neural Likelihood Estimation (NLE) class to train a neural density estimator to perform NLE.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">re</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">copy</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">warnings</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Iterable</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">distrax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">flax.linen</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">nn</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jnp</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">jax.random</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">jr</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpyro.distributions</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dist</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxtyping</span><span class="w"> </span><span class="kn">import</span> <span class="n">Array</span><span class="p">,</span> <span class="n">Float</span><span class="p">,</span> <span class="n">PyTree</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">jaxili</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.loss</span><span class="w"> </span><span class="kn">import</span> <span class="n">loss_nll_nle</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.model</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">ConditionalMAF</span><span class="p">,</span>
    <span class="n">ConditionalRealNVP</span><span class="p">,</span>
    <span class="n">MixtureDensityNetwork</span><span class="p">,</span>
    <span class="n">NDE_w_Standardization</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.compressor</span><span class="w"> </span><span class="kn">import</span> <span class="n">Identity</span><span class="p">,</span> <span class="n">Standardizer</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.posterior</span><span class="w"> </span><span class="kn">import</span> <span class="n">MCMCPosterior</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.posterior.mcmc_posterior</span><span class="w"> </span><span class="kn">import</span> <span class="n">nuts_numpyro_kwargs_default</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.train</span><span class="w"> </span><span class="kn">import</span> <span class="n">TrainerModule</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.utils</span><span class="w"> </span><span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_density_estimator</span><span class="p">,</span> <span class="n">create_data_loader</span><span class="p">,</span> <span class="n">validate_theta_x</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">jaxili.inventory.func_dict</span><span class="w"> </span><span class="kn">import</span> <span class="n">jax_nn_dict</span><span class="p">,</span> <span class="n">jaxili_loss_dict</span><span class="p">,</span> <span class="n">jaxili_nn_dict</span>

<span class="n">default_maf_hparams</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;n_layers&quot;</span><span class="p">:</span> <span class="mi">5</span><span class="p">,</span>
    <span class="s2">&quot;layers&quot;</span><span class="p">:</span> <span class="p">[</span><span class="mi">50</span><span class="p">,</span> <span class="mi">50</span><span class="p">],</span>
    <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="n">jax</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">,</span>
    <span class="s2">&quot;use_reverse&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
    <span class="s2">&quot;seed&quot;</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
<span class="p">}</span>


<div class="viewcode-block" id="NLE">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">NLE</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    NLE.</span>

<span class="sd">    Base class for Neural Likelihood Estimation (NLE) methods.</span>
<span class="sd">    Default configuration used a `ConditionalMAF` to learn the likelihood function.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from jaxili.inference import NLE</span>
<span class="sd">    &gt;&gt;&gt; inference = NLE()</span>
<span class="sd">    &gt;&gt;&gt; theta, x = ...  # Load parameters and simulation outputs</span>
<span class="sd">    &gt;&gt;&gt; inference.append_simulations(theta, x) #Push your simulations in the trainer</span>
<span class="sd">    &gt;&gt;&gt; inference.train() #Train your density estimator</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">model_class</span><span class="p">:</span> <span class="n">jaxili</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">NDENetwork</span> <span class="o">=</span> <span class="n">ConditionalMAF</span><span class="p">,</span>
        <span class="n">logging_level</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;WARNING&quot;</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">model_hparams</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="n">default_maf_hparams</span><span class="p">,</span>
        <span class="n">loss_fn</span><span class="p">:</span> <span class="n">Callable</span> <span class="o">=</span> <span class="n">loss_nll_nle</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build class for Neural Likelihood Estimation (NLE) methods.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model_class : jaxili.model.NDENetwork</span>
<span class="sd">            Class of the neural density estimator to use. Default: ConditionalMAF.</span>
<span class="sd">        model_hparams : Dict[str, Any]</span>
<span class="sd">            Hyperparameters to use for the model.</span>
<span class="sd">        logging_level: Union[int, str], optional</span>
<span class="sd">            Logging level to use. Default is &quot;WARNING&quot;.</span>
<span class="sd">        show_progress_bar : bool, optional</span>
<span class="sd">            Whether to show a progress bar during training. Default is True.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_class</span> <span class="o">=</span> <span class="n">model_class</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span> <span class="o">=</span> <span class="n">model_hparams</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_logging_level</span> <span class="o">=</span> <span class="n">logging_level</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span> <span class="o">=</span> <span class="n">verbose</span>

<div class="viewcode-block" id="NLE.set_model_hparams">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.set_model_hparams">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_model_hparams</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hparams</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the hyperparameters of the model.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        hparams : Dict[str, Any]</span>
<span class="sd">            Hyperparameters to use for the model.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span> <span class="o">=</span> <span class="n">hparams</span></div>


<div class="viewcode-block" id="NLE.set_loss_fn">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.set_loss_fn">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_loss_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the loss function to use for training.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        loss_fn : Callable</span>
<span class="sd">            Loss function to use for training.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span> <span class="o">=</span> <span class="n">loss_fn</span></div>


<div class="viewcode-block" id="NLE.set_dataset">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.set_dataset">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_dataset</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the dataset to use for training, validation or testing.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dataset : data.Dataset</span>
<span class="sd">            Dataset to use.</span>
<span class="sd">        type : str</span>
<span class="sd">            Type of the dataset. Can be &#39;train&#39;, &#39;val&#39; or &#39;test&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">type</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="s2">&quot;val&quot;</span><span class="p">,</span>
            <span class="s2">&quot;test&quot;</span><span class="p">,</span>
        <span class="p">],</span> <span class="s2">&quot;Type should be &#39;train&#39;, &#39;val&#39; or &#39;test&#39;.&quot;</span>

        <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;val&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_val_dataset</span> <span class="o">=</span> <span class="n">dataset</span>
        <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_test_dataset</span> <span class="o">=</span> <span class="n">dataset</span></div>


<div class="viewcode-block" id="NLE.set_dataloader">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.set_dataloader">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">set_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataloader</span><span class="p">,</span> <span class="nb">type</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the dataloader to use for training, validation or testing.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        dataloader : data.DataLoader</span>
<span class="sd">            dataloader to use.</span>
<span class="sd">        type : str</span>
<span class="sd">            Type of the dataloader. Can be &#39;train&#39;, &#39;val&#39; or &#39;test&#39;.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">assert</span> <span class="nb">type</span> <span class="ow">in</span> <span class="p">[</span>
            <span class="s2">&quot;train&quot;</span><span class="p">,</span>
            <span class="s2">&quot;val&quot;</span><span class="p">,</span>
            <span class="s2">&quot;test&quot;</span><span class="p">,</span>
        <span class="p">],</span> <span class="s2">&quot;Type should be &#39;train&#39;, &#39;val&#39; or &#39;test&#39;.&quot;</span>

        <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataloader</span> <span class="o">=</span> <span class="n">dataloader</span>
        <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;val&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_val_dataloader</span> <span class="o">=</span> <span class="n">dataloader</span>
        <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;test&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_test_dataloader</span> <span class="o">=</span> <span class="n">dataloader</span></div>


<div class="viewcode-block" id="NLE.append_simulations">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.append_simulations">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">append_simulations</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">theta</span><span class="p">:</span> <span class="n">Array</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">Array</span><span class="p">,</span>
        <span class="n">train_test_split</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span>
        <span class="n">key</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">PyTree</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Store parameters and simulation outputs to use them for later training.</span>

<span class="sd">        Data is stored in a Dataset object from `jax-dataloader`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        theta : Array</span>
<span class="sd">            Parameters of the simulations.</span>
<span class="sd">        x : Array</span>
<span class="sd">            Simulation outputs.</span>
<span class="sd">        train_test_split : Iterable[float], optional</span>
<span class="sd">            Fractions to split the dataset into training, validation and test sets.</span>
<span class="sd">            Should be of length 2 or 3. A length 2 list will not generate a test set. Default is [0.7, 0.2, 0.1].</span>
<span class="sd">        key : PyTree, optional</span>
<span class="sd">            Key to use for the random permutation of the dataset. Default is None.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Verify theta and x typing and size of the dataset</span>
        <span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">num_sims</span> <span class="o">=</span> <span class="n">validate_theta_x</span><span class="p">(</span><span class="n">theta</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Inputs are valid.&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Appending </span><span class="si">{</span><span class="n">num_sims</span><span class="si">}</span><span class="s2"> simulations to the dataset.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_dim_params</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_dim_cond</span> <span class="o">=</span> <span class="n">theta</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_num_sims</span> <span class="o">=</span> <span class="n">num_sims</span>

        <span class="c1"># Split the dataset into training, validation and test sets</span>
        <span class="n">is_test_set</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_test_split</span><span class="p">)</span> <span class="o">==</span> <span class="mi">3</span>
        <span class="k">if</span> <span class="n">is_test_set</span><span class="p">:</span>
            <span class="n">train_fraction</span><span class="p">,</span> <span class="n">val_fraction</span><span class="p">,</span> <span class="n">test_fraction</span> <span class="o">=</span> <span class="n">train_test_split</span>
            <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span>
                <span class="n">train_fraction</span> <span class="o">+</span> <span class="n">val_fraction</span> <span class="o">+</span> <span class="n">test_fraction</span><span class="p">,</span> <span class="mf">1.0</span>
            <span class="p">),</span> <span class="s2">&quot;The sum of the split fractions should be 1.&quot;</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_test_split</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
            <span class="n">train_fraction</span><span class="p">,</span> <span class="n">val_fraction</span> <span class="o">=</span> <span class="n">train_test_split</span>
            <span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">isclose</span><span class="p">(</span>
                <span class="n">train_fraction</span> <span class="o">+</span> <span class="n">val_fraction</span><span class="p">,</span> <span class="mf">1.0</span>
            <span class="p">),</span> <span class="s2">&quot;The sum of the split fractions should be 1.&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;train_test_split should have 2 or 3 elements.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">key</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">key</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">PRNGKey</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span><span class="p">))</span>
        <span class="n">index_permutation</span> <span class="o">=</span> <span class="n">jr</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">num_sims</span><span class="p">)</span>

        <span class="n">train_idx</span> <span class="o">=</span> <span class="n">index_permutation</span><span class="p">[:</span> <span class="nb">int</span><span class="p">(</span><span class="n">train_fraction</span> <span class="o">*</span> <span class="n">num_sims</span><span class="p">)]</span>
        <span class="n">val_idx</span> <span class="o">=</span> <span class="n">index_permutation</span><span class="p">[</span>
            <span class="nb">int</span><span class="p">(</span><span class="n">train_fraction</span> <span class="o">*</span> <span class="n">num_sims</span><span class="p">)</span> <span class="p">:</span> <span class="nb">int</span><span class="p">(</span>
                <span class="p">(</span><span class="n">train_fraction</span> <span class="o">+</span> <span class="n">val_fraction</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_sims</span>
            <span class="p">)</span>
        <span class="p">]</span>
        <span class="k">if</span> <span class="n">is_test_set</span><span class="p">:</span>
            <span class="n">test_idx</span> <span class="o">=</span> <span class="n">index_permutation</span><span class="p">[</span>
                <span class="nb">int</span><span class="p">((</span><span class="n">train_fraction</span> <span class="o">+</span> <span class="n">val_fraction</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_sims</span><span class="p">)</span> <span class="p">:</span>
            <span class="p">]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">set_dataset</span><span class="p">(</span><span class="n">jdl</span><span class="o">.</span><span class="n">ArrayDataset</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]),</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_dataset</span><span class="p">(</span><span class="n">jdl</span><span class="o">.</span><span class="n">ArrayDataset</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">val_idx</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">val_idx</span><span class="p">]),</span> <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;val&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">set_dataset</span><span class="p">(</span>
            <span class="n">jdl</span><span class="o">.</span><span class="n">ArrayDataset</span><span class="p">(</span><span class="n">theta</span><span class="p">[</span><span class="n">test_idx</span><span class="p">],</span> <span class="n">x</span><span class="p">[</span><span class="n">test_idx</span><span class="p">])</span> <span class="k">if</span> <span class="n">is_test_set</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
            <span class="nb">type</span><span class="o">=</span><span class="s2">&quot;test&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Dataset split into training, validation and test sets.&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Training set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_idx</span><span class="p">)</span><span class="si">}</span><span class="s2"> simulations.&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Validation set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">val_idx</span><span class="p">)</span><span class="si">}</span><span class="s2"> simulations.&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">is_test_set</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Test set: </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">test_idx</span><span class="p">)</span><span class="si">}</span><span class="s2"> simulations.&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_create_data_loader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create DataLoaders for the training, validation and test datasets. Can only be executed after appending simulations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        batch_size : int</span>
<span class="sd">            Batch size to use for the DataLoader. Default is 128.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No training dataset found. Please append simulations first.&quot;</span>
            <span class="p">)</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_val_dataset</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No validation dataset found. Please append simulations first.&quot;</span>
            <span class="p">)</span>

        <span class="n">train</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span> <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_dataset</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span><span class="p">]</span>
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Creating DataLoaders with batch_size </span><span class="si">{</span><span class="n">batch_size</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_dataset</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_loader</span> <span class="o">=</span> <span class="n">create_data_loader</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_dataset</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_test_loader</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_val_loader</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_loader</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">create_data_loader</span><span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_val_dataset</span><span class="p">,</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">_test_dataset</span><span class="p">,</span>
                    <span class="n">train</span><span class="o">=</span><span class="n">train</span><span class="p">,</span>
                    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="p">)</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_build_neural_network</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">z_score_theta</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">z_score_x</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">embedding_net</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">,</span>
        <span class="n">embedding_hparams</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the neural network for the density estimator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        z_score_theta : bool, optional</span>
<span class="sd">            Whether to z-score the parameters. Default is True.</span>
<span class="sd">        z_score_x : bool, optional</span>
<span class="sd">            Whether to z-score the simulation outputs. Default is True.</span>
<span class="sd">        embedding_net : nn.Module, optional</span>
<span class="sd">            Neural network to use for embedding. Default is nn.Identity().</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[!] Building the neural network.&quot;</span><span class="p">)</span>

        <span class="c1"># Check if the model class and hparams are correct</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_class</span> <span class="o">==</span> <span class="n">ConditionalMAF</span><span class="p">:</span>
            <span class="n">check_hparams_maf</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_class</span> <span class="o">==</span> <span class="n">ConditionalRealNVP</span><span class="p">:</span>
            <span class="n">check_hparams_realnvp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_class</span> <span class="o">==</span> <span class="n">MixtureDensityNetwork</span><span class="p">:</span>
            <span class="n">check_hparams_mdn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Model class </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">model_class</span><span class="si">}</span><span class="s2"> is not a base class of JaxILI.</span><span class="se">\n</span><span class="s2"> Check that the hyperparameters of your network are consistent.&quot;</span><span class="p">,</span>
                <span class="ne">Warning</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No training dataset found. Please append simulations first.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Check if z-score is required for theta.</span>
        <span class="k">if</span> <span class="n">z_score_theta</span><span class="p">:</span>
            <span class="n">shift</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span><span class="p">[:][</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span><span class="p">[:][</span><span class="mi">0</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">min_std</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;min_std&quot;</span><span class="p">,</span> <span class="mf">1e-14</span><span class="p">)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">scale</span> <span class="o">&lt;</span> <span class="n">min_std</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">min_std</span><span class="p">)</span>
            <span class="n">standardizer</span> <span class="o">=</span> <span class="n">Standardizer</span><span class="p">(</span><span class="n">shift</span><span class="p">,</span> <span class="n">scale</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">standardizer</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">()</span>

        <span class="k">if</span> <span class="n">embedding_net</span> <span class="o">==</span> <span class="n">Identity</span><span class="p">:</span>
            <span class="n">embedding_net</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">embedding_hparams</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                    <span class="s2">&quot;An embedding net has been specified but not its hyperparameters. Creating an embedding of the instance `Identity` instead.&quot;</span>
                <span class="p">)</span>
                <span class="n">embedding_net</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">()</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">embedding_net</span> <span class="o">=</span> <span class="n">embedding_net</span><span class="p">(</span><span class="o">**</span><span class="n">embedding_hparams</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">([</span><span class="n">standardizer</span><span class="p">,</span> <span class="n">embedding_net</span><span class="p">])</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">embedding_net</span><span class="p">,</span> <span class="n">Identity</span><span class="p">):</span>
            <span class="n">n_cond</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dim_cond</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">n_cond</span> <span class="o">=</span> <span class="n">embedding_net</span><span class="o">.</span><span class="n">output_size</span>

        <span class="c1"># Check if z-score is required for x.</span>
        <span class="n">shift</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dim_params</span><span class="p">)</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_dim_params</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">z_score_x</span><span class="p">:</span>
            <span class="n">shift</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span><span class="p">[:][</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">jnp</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span><span class="p">[:][</span><span class="mi">1</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">min_std</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;min_std&quot;</span><span class="p">,</span> <span class="mf">1e-14</span><span class="p">)</span>
            <span class="n">scale</span> <span class="o">=</span> <span class="n">scale</span><span class="o">.</span><span class="n">at</span><span class="p">[</span><span class="n">scale</span> <span class="o">&lt;</span> <span class="n">min_std</span><span class="p">]</span><span class="o">.</span><span class="n">set</span><span class="p">(</span><span class="n">min_std</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_transformation_hparams</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;shift&quot;</span><span class="p">:</span> <span class="n">shift</span><span class="p">,</span> <span class="s2">&quot;scale&quot;</span><span class="p">:</span> <span class="n">scale</span><span class="p">}</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_transformation</span> <span class="o">=</span> <span class="n">distrax</span><span class="o">.</span><span class="n">ScalarAffine</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="n">scale</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="n">shift</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span><span class="p">[</span><span class="s2">&quot;n_in&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dim_params</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span><span class="p">[</span><span class="s2">&quot;n_cond&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">n_cond</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_nde</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_class</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span><span class="p">)</span>

        <span class="n">model</span> <span class="o">=</span> <span class="n">NDE_w_Standardization</span><span class="p">(</span>
            <span class="n">nde</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_nde</span><span class="p">,</span>
            <span class="n">embedding_net</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_embedding_net</span><span class="p">,</span>
            <span class="n">transformation</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_transformation</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">model</span>

<div class="viewcode-block" id="NLE.create_trainer">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.create_trainer">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">create_trainer</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">optimizer_hparams</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">],</span>
        <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">42</span><span class="p">,</span>
        <span class="n">logger_params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">check_val_every_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a TrainerModule for the density estimator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        optimizer_hparams : Dict[str, Any]</span>
<span class="sd">            Hyperparameters to use for the optimizer.</span>
<span class="sd">        loss_fn : Callable</span>
<span class="sd">            Loss function to use for training.</span>
<span class="sd">        exmp_input : Any</span>
<span class="sd">            Example input to use for the model.</span>
<span class="sd">        seed : int, optional</span>
<span class="sd">            Seed to use for the trainer. Default is 42.</span>
<span class="sd">        logger_params : Dict[str, Any], optional</span>
<span class="sd">            Parameters to use for the logger. Default is None.</span>
<span class="sd">        debug : bool, optional</span>
<span class="sd">            Whether to use debug mode. Default is False.</span>
<span class="sd">        check_val_every_epoch : int, optional</span>
<span class="sd">            Frequency at which to check the validation loss. Default is 1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_nde</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">z_score_theta</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;z_score_theta&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">z_score_x</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;z_score_x&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
            <span class="n">embedding_net</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;embedding_net&quot;</span><span class="p">,</span> <span class="n">Identity</span><span class="p">)</span>
            <span class="n">embedding_net_hparams</span> <span class="o">=</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;embedding_hparams&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
            <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_build_neural_network</span><span class="p">(</span>
                <span class="n">z_score_theta</span><span class="o">=</span><span class="n">z_score_theta</span><span class="p">,</span>
                <span class="n">z_score_x</span><span class="o">=</span><span class="n">z_score_x</span><span class="p">,</span>
                <span class="n">embedding_net</span><span class="o">=</span><span class="n">embedding_net</span><span class="p">,</span>
                <span class="n">embedding_hparams</span><span class="o">=</span><span class="n">embedding_net_hparams</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">nde_w_std_hparams</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;nde&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_nde</span><span class="p">,</span>
            <span class="s2">&quot;embedding_net&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_embedding_net</span><span class="p">,</span>
            <span class="s2">&quot;transformation&quot;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_transformation</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="n">exmp_input</span> <span class="o">=</span> <span class="p">(</span>
            <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dim_cond</span><span class="p">)),</span>
            <span class="n">jnp</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_dim_params</span><span class="p">)),</span>
        <span class="p">)</span>  <span class="c1"># Example will be reversed in the trainer.</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[!] Creating the Trainer module.&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">TrainerModule</span><span class="p">(</span>
            <span class="n">model_class</span><span class="o">=</span><span class="n">NDE_w_Standardization</span><span class="p">,</span>
            <span class="n">model_hparams</span><span class="o">=</span><span class="n">nde_w_std_hparams</span><span class="p">,</span>
            <span class="n">optimizer_hparams</span><span class="o">=</span><span class="n">optimizer_hparams</span><span class="p">,</span>
            <span class="n">loss_fn</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_loss_fn</span><span class="p">,</span>
            <span class="n">exmp_input</span><span class="o">=</span><span class="n">exmp_input</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
            <span class="n">logger_params</span><span class="o">=</span><span class="n">logger_params</span><span class="p">,</span>
            <span class="n">enable_progress_bar</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">debug</span><span class="o">=</span><span class="n">debug</span><span class="p">,</span>
            <span class="n">check_val_every_epoch</span><span class="o">=</span><span class="n">check_val_every_epoch</span><span class="p">,</span>
            <span class="n">nde_class</span><span class="o">=</span><span class="s2">&quot;NLE&quot;</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s2">&quot;nde_hparams&quot;</span><span class="p">:</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span><span class="p">)})</span>
        <span class="c1"># Check if there is an activation function to rename</span>
        <span class="k">if</span> <span class="s2">&quot;activation&quot;</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_model_hparams</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;nde_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">config</span><span class="p">[</span>
                <span class="s2">&quot;nde_hparams&quot;</span>
            <span class="p">][</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
            <span class="p">{</span><span class="s2">&quot;transformation_hparams&quot;</span><span class="p">:</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_transformation_hparams</span><span class="p">)}</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">embedding_net_hparams</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
                <span class="p">{</span><span class="s2">&quot;embedding_hparams&quot;</span><span class="p">:</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">embedding_net_hparams</span><span class="p">)}</span>
            <span class="p">)</span>
            <span class="c1"># Check if there is an activation function to rename</span>
            <span class="k">if</span> <span class="s2">&quot;activation&quot;</span> <span class="ow">in</span> <span class="n">embedding_net_hparams</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;embedding_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">config</span><span class="p">[</span><span class="s2">&quot;embedding_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span><span class="o">.</span><span class="vm">__name__</span>
                <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">write_config</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">log_dir</span><span class="p">)</span></div>


<div class="viewcode-block" id="NLE.train">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.train">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">train</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">training_batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
        <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">5e-4</span><span class="p">,</span>
        <span class="n">patience</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">20</span><span class="p">,</span>
        <span class="n">num_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="o">**</span><span class="mi">31</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">check_val_every_epoch</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the density estimator to approximate the distribution $p(\theta|x)$.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        training_batch_size : int, optional</span>
<span class="sd">            Batch size to use during training. Default is 50.</span>
<span class="sd">        learning_rate: float, optional</span>
<span class="sd">            Learning rate to use during training. Default is 5e-4.</span>
<span class="sd">        patience: int, optional</span>
<span class="sd">            Number of epochs to wait before early stopping. Default is 20.</span>
<span class="sd">        num_epochs: int, optional</span>
<span class="sd">            Maximum number of epochs to train. Default is 2**31 - 1.</span>
<span class="sd">        check_val_every_epoch: int, optional</span>
<span class="sd">            Frequency at which to check the validation loss. Default is 1.</span>
<span class="sd">        **kwargs : dict, optional</span>
<span class="sd">            Additional keyword arguments for training customization:</span>

<span class="sd">            - optimizer_name (str): Name of the optimizer to use (default: &#39;adam&#39;).</span>
<span class="sd">            - gradient_clip (float): Value for gradient clipping (default: 5.0).</span>
<span class="sd">            - warmup (float): Warmup proportion for learning rate scheduling (default: 0.1).</span>
<span class="sd">            - weight_decay (float): Weight decay (L2 regularization) (default: 0.0).</span>
<span class="sd">            - checkpoint_path (str): Directory to save training checkpoints (default: &#39;checkpoints/&#39;).</span>
<span class="sd">            - log_dir (str or None): Directory for logging (default: None).</span>
<span class="sd">            - logger_type (str): Type of logger to use (default: &#39;TensorBoard&#39;).</span>
<span class="sd">            - seed (int): Random seed for reproducibility (default: 42).</span>
<span class="sd">            - debug (bool): Whether to run in debug mode (default: False).</span>
<span class="sd">            - min_delta (float): Minimum change in validation loss to qualify as improvement (default: 1e-3).</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        metrics : Dict[str, Any]</span>
<span class="sd">            Dictionary containing the training, validation and test losses.</span>
<span class="sd">        density_estimator : nn.Module</span>
<span class="sd">            The trained density estimator.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_dataset</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;No training dataset found. Please append simulations first.&quot;</span>
            <span class="p">)</span>

        <span class="c1"># Create the dataloaders to perform the training</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_train_loader</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_create_data_loader</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">training_batch_size</span><span class="p">)</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train_model</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_loader</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_val_loader</span><span class="p">,</span>
                <span class="n">test_loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_test_loader</span><span class="p">,</span>
                <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
                <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="n">optimizer_hparams</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;lr&quot;</span><span class="p">:</span> <span class="n">learning_rate</span><span class="p">,</span>
                <span class="s2">&quot;optimizer_name&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;optimizer_name&quot;</span><span class="p">,</span> <span class="s2">&quot;adam&quot;</span><span class="p">),</span>
                <span class="s2">&quot;gradient_clip&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;gradient_clip&quot;</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">),</span>
                <span class="s2">&quot;warmup&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;warmup&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">),</span>
                <span class="s2">&quot;weight_decay&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;weight_decay&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
            <span class="p">}</span>

            <span class="n">logger_params</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s2">&quot;base_log_dir&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;checkpoint_path&quot;</span><span class="p">,</span> <span class="s2">&quot;checkpoints/&quot;</span><span class="p">),</span>
                <span class="s2">&quot;log_dir&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;log_dir&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span>
                <span class="s2">&quot;logger_type&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;logger_type&quot;</span><span class="p">,</span> <span class="s2">&quot;TensorBoard&quot;</span><span class="p">),</span>
            <span class="p">}</span>

            <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_trainer</span><span class="p">(</span>
                <span class="n">optimizer_hparams</span><span class="o">=</span><span class="n">optimizer_hparams</span><span class="p">,</span>
                <span class="n">seed</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;seed&quot;</span><span class="p">,</span> <span class="mi">42</span><span class="p">),</span>
                <span class="n">logger_params</span><span class="o">=</span><span class="n">logger_params</span><span class="p">,</span>
                <span class="n">debug</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;debug&quot;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span>
                <span class="n">check_val_every_epoch</span><span class="o">=</span><span class="n">check_val_every_epoch</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[!] Training the density estimator.&quot;</span><span class="p">)</span>
            <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">train_model</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_train_loader</span><span class="p">,</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">_val_loader</span><span class="p">,</span>
                <span class="n">test_loader</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_test_loader</span><span class="p">,</span>
                <span class="n">num_epochs</span><span class="o">=</span><span class="n">num_epochs</span><span class="p">,</span>
                <span class="n">patience</span><span class="o">=</span><span class="n">patience</span><span class="p">,</span>
                <span class="n">min_delta</span><span class="o">=</span><span class="n">kwargs</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;min_delta&quot;</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">),</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Training loss: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;train/loss&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Validation loss: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;val/loss&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_test_loader</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[!] Test loss: </span><span class="si">{</span><span class="n">metrics</span><span class="p">[</span><span class="s1">&#39;test/loss&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">density_estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">bind_model</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">metrics</span><span class="p">,</span> <span class="n">density_estimator</span></div>


<div class="viewcode-block" id="NLE.build_posterior">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.build_posterior">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">build_posterior</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">prior_distr</span><span class="p">:</span> <span class="n">dist</span><span class="o">.</span><span class="n">Distribution</span><span class="p">,</span>
        <span class="n">verbose</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">bool</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">x</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Array</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">mcmc_method</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;nuts_numpyro&quot;</span><span class="p">,</span>
        <span class="n">mcmc_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]]</span> <span class="o">=</span> <span class="n">nuts_numpyro_kwargs_default</span><span class="p">,</span>
    <span class="p">):</span>
<span class="w">        </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Build the posterior distribution $p(\theta|x)$ using the trained density estimator.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prior_distr : dist.Distribution</span>
<span class="sd">            Numpyro distribution sampling the prior used to estimate the parameters.</span>
<span class="sd">        verbose : bool, optional</span>
<span class="sd">            Whether to print information. Default is the verbiose boolean of the trainer.</span>
<span class="sd">        x : Array, optional</span>
<span class="sd">            The data used to condition the posterior. Default is None.</span>
<span class="sd">        mcmc_method : str, optional</span>
<span class="sd">            The MCMC method to use. Default is &#39;nuts_numpyro&#39;.</span>
<span class="sd">        mcmc_kwargs : dict, optional</span>
<span class="sd">            The jeyword arguments to sample from the posterior.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        posterior : NeuralPosterior</span>
<span class="sd">            The posterior distribution allowing to sample and evaluate the unnormalized log-probability.</span>
<span class="sd">            The sampling is performed using MCMC methods.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">trainer</span>
        <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;No trainer found. You must first create a trainer.&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">verbose</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span>
        <span class="n">posterior</span> <span class="o">=</span> <span class="n">MCMCPosterior</span><span class="p">(</span>
            <span class="n">prior_distr</span><span class="o">=</span><span class="n">prior_distr</span><span class="p">,</span>
            <span class="n">model</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
            <span class="n">state</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">state</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span>
            <span class="n">mcmc_method</span><span class="o">=</span><span class="n">mcmc_method</span><span class="p">,</span>
            <span class="n">mcmc_kwargs</span><span class="o">=</span><span class="n">mcmc_kwargs</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span>
                <span class="sa">r</span><span class="s2">&quot;[!] Posterior $p(\theta| x)$ built. The class MCMCPosterior is used to sample and evaluate the log probability.\n The sampling is performed using MCMC methods.&quot;</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">posterior</span></div>


<div class="viewcode-block" id="NLE.load_from_checkpoints">
<a class="viewcode-back" href="../../../jaxili.inference.nle.html#jaxili.inference.nle.NLE.load_from_checkpoints">[docs]</a>
    <span class="nd">@classmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">load_from_checkpoints</span><span class="p">(</span>
        <span class="bp">cls</span><span class="p">,</span> <span class="n">checkpoint</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">exmp_input</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">embedding_net_class</span><span class="o">=</span><span class="n">Identity</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a NLE object where the TrainerModule is loading the already existing weights for the neural network.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        nde_class: NDENetwork</span>
<span class="sd">            Class used to create the neural density estimator</span>
<span class="sd">        checkpoint: str</span>
<span class="sd">            Folder in which the checkpoint and hyperparameter file is stored</span>
<span class="sd">        exmp_input : Any</span>
<span class="sd">            An input to the model with which the shapes are inferred.</span>
<span class="sd">        embedding_net_class: nn.Module</span>
<span class="sd">            Class used to create the embedding net. (Default: Identity)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A NLE object containing a model with the pre-trained weights loaded.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">hparams_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="s2">&quot;hparams.json&quot;</span><span class="p">)</span>
        <span class="k">assert</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">isfile</span><span class="p">(</span><span class="n">hparams_file</span><span class="p">),</span> <span class="s2">&quot;Could not find hparams file.&quot;</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">hparams_file</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
            <span class="n">hparams</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;model_class&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">NDE_w_Standardization</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="p">),</span> <span class="s2">&quot;The model has not been trained with NDE_w_Standardization. Check the checkpoint path is correct.&quot;</span>
        <span class="n">hparams</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;model_class&quot;</span><span class="p">)</span>

        <span class="c1"># Check that the embedding class name is correct.</span>
        <span class="n">embedding_str</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;model_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;embedding_net&quot;</span><span class="p">]</span>
        <span class="c1"># Find all class names in the layers list</span>
        <span class="n">class_names</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">findall</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(\w+)\s*\(&quot;</span><span class="p">,</span> <span class="n">embedding_str</span><span class="p">)</span>

        <span class="c1"># The first entry is &quot;Sequential&quot;, so we take the next two</span>
        <span class="n">embedding_classes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">class_</span> <span class="k">for</span> <span class="n">class_</span> <span class="ow">in</span> <span class="n">class_names</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span> <span class="k">if</span> <span class="n">class_</span> <span class="o">!=</span> <span class="s2">&quot;Array&quot;</span>
        <span class="p">]</span>  <span class="c1"># Skip &quot;Sequential&quot;</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">embedding_classes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">==</span> <span class="n">embedding_net_class</span><span class="o">.</span><span class="vm">__name__</span>
        <span class="p">),</span> <span class="s2">&quot;The embedding class does not match. Check that you are using the correct architecture.&quot;</span>

        <span class="c1"># Check if the loss function is correct.</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">]</span> <span class="ow">in</span> <span class="n">jaxili_loss_dict</span>
        <span class="p">),</span> <span class="s2">&quot;Unknown loss function. Check that the loss function you used comes from `jax.nn`.&quot;</span>
        <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">jaxili_loss_dict</span><span class="p">[</span><span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">]]</span>
        <span class="c1"># Create the NDE</span>
        <span class="c1"># Extract the nde string</span>
        <span class="n">nde_str</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;model_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;nde&quot;</span><span class="p">]</span>

        <span class="c1"># Use regex to extract the class name</span>
        <span class="n">nde_class_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">match</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;(\w+)\s*\(&quot;</span><span class="p">,</span> <span class="n">nde_str</span><span class="p">)</span>

        <span class="c1"># Get the class name</span>
        <span class="n">nde_class_name</span> <span class="o">=</span> <span class="n">nde_class_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">nde_class_match</span> <span class="k">else</span> <span class="kc">None</span>

        <span class="n">nde_class</span> <span class="o">=</span> <span class="n">jaxili_nn_dict</span><span class="p">[</span><span class="n">nde_class_name</span><span class="p">]</span>
        <span class="n">nde_hparams</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;nde_hparams&quot;</span><span class="p">]</span>
        <span class="k">if</span> <span class="s2">&quot;activation&quot;</span> <span class="ow">in</span> <span class="n">nde_hparams</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">nde_hparams</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">jax_nn_dict</span><span class="p">[</span><span class="n">nde_hparams</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">]]</span>

        <span class="c1"># Create object from the class NLE</span>
        <span class="n">inference</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">(</span>
            <span class="n">model_class</span><span class="o">=</span><span class="n">nde_class</span><span class="p">,</span> <span class="n">model_hparams</span><span class="o">=</span><span class="n">nde_hparams</span><span class="p">,</span> <span class="n">loss_fn</span><span class="o">=</span><span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;loss_fn&quot;</span><span class="p">]</span>
        <span class="p">)</span>

        <span class="c1"># Create the NDE</span>
        <span class="n">inference</span><span class="o">.</span><span class="n">_nde</span> <span class="o">=</span> <span class="n">nde_class</span><span class="p">(</span><span class="o">**</span><span class="n">nde_hparams</span><span class="p">)</span>

        <span class="c1"># Regenerate the embedding net</span>
        <span class="k">if</span> <span class="n">embedding_classes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Identity&quot;</span><span class="p">:</span>
            <span class="n">standardizer</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">embedding_classes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s2">&quot;Standardizer&quot;</span><span class="p">:</span>
            <span class="n">embedding_net_str</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;model_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;embedding_net&quot;</span><span class="p">]</span>

            <span class="c1"># Regular expressions to extract mean and std arrays</span>
            <span class="n">mean_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;mean\s*=\s*Array\((\[.*?\])&quot;</span><span class="p">,</span> <span class="n">embedding_net_str</span><span class="p">)</span>
            <span class="n">std_match</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">search</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;std\s*=\s*Array\((\[.*?\])&quot;</span><span class="p">,</span> <span class="n">embedding_net_str</span><span class="p">)</span>

            <span class="c1"># Convert extracted values into NumPy arrays</span>
            <span class="n">mean_array</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="n">mean_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;[]&quot;</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;, &quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">mean_match</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>
            <span class="n">std_array</span> <span class="o">=</span> <span class="p">(</span>
                <span class="n">np</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="n">std_match</span><span class="o">.</span><span class="n">group</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;[]&quot;</span><span class="p">),</span> <span class="n">sep</span><span class="o">=</span><span class="s2">&quot;, &quot;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">std_match</span>
                <span class="k">else</span> <span class="kc">None</span>
            <span class="p">)</span>

            <span class="n">standardizer</span> <span class="o">=</span> <span class="n">Standardizer</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">mean_array</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="n">std_array</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The first class of the embedding net should be `Identity` or `Standardizer`.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">embedding_classes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="s2">&quot;Identity&quot;</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;embedding_hparams&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">hparams</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The embedding net hyperparameters can&#39;t be find. Check that you are using the correct checkpoint path.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="s2">&quot;activation&quot;</span> <span class="ow">in</span> <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;embedding_hparams&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;embedding_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">jax_nn_dict</span><span class="p">[</span>
                    <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;embedding_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span>
                <span class="p">]</span>
            <span class="n">embedding_net</span> <span class="o">=</span> <span class="n">embedding_net_class</span><span class="p">(</span><span class="o">**</span><span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;embedding_hparams&quot;</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">embedding_net</span> <span class="o">=</span> <span class="n">Identity</span><span class="p">()</span>

        <span class="n">inference</span><span class="o">.</span><span class="n">_embedding_net</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="p">[</span><span class="n">standardizer</span><span class="p">,</span> <span class="n">embedding_net</span><span class="p">])</span>

        <span class="c1"># Regenerate the transformation of the parameters</span>
        <span class="n">shift_str</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;transformation_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;shift&quot;</span><span class="p">]</span>
        <span class="n">shift_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">shift_str</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;[]&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>

        <span class="n">scale_str</span> <span class="o">=</span> <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;transformation_hparams&quot;</span><span class="p">][</span><span class="s2">&quot;scale&quot;</span><span class="p">]</span>
        <span class="n">scale_list</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">scale_str</span><span class="o">.</span><span class="n">strip</span><span class="p">(</span><span class="s2">&quot;[]&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">()]</span>

        <span class="n">inference</span><span class="o">.</span><span class="n">_transformation</span> <span class="o">=</span> <span class="n">distrax</span><span class="o">.</span><span class="n">ScalarAffine</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">shift_list</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scale_list</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="n">model_hparams</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;nde&quot;</span><span class="p">:</span> <span class="n">inference</span><span class="o">.</span><span class="n">_nde</span><span class="p">,</span>
            <span class="s2">&quot;embedding_net&quot;</span><span class="p">:</span> <span class="n">inference</span><span class="o">.</span><span class="n">_embedding_net</span><span class="p">,</span>
            <span class="s2">&quot;transformation&quot;</span><span class="p">:</span> <span class="n">inference</span><span class="o">.</span><span class="n">_transformation</span><span class="p">,</span>
        <span class="p">}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;logger_params&quot;</span><span class="p">]:</span>
            <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;logger_params&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
        <span class="n">hparams</span><span class="p">[</span><span class="s2">&quot;logger_params&quot;</span><span class="p">][</span><span class="s2">&quot;log_dir&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">checkpoint</span>
        <span class="n">hparams</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s2">&quot;model_hparams&quot;</span><span class="p">)</span>

        <span class="n">inference</span><span class="o">.</span><span class="n">trainer</span> <span class="o">=</span> <span class="n">TrainerModule</span><span class="p">(</span>
            <span class="n">model_class</span><span class="o">=</span><span class="n">NDE_w_Standardization</span><span class="p">,</span>
            <span class="n">exmp_input</span><span class="o">=</span><span class="n">exmp_input</span><span class="p">,</span>
            <span class="n">model_hparams</span><span class="o">=</span><span class="n">model_hparams</span><span class="p">,</span>
            <span class="n">nde_class</span><span class="o">=</span><span class="s2">&quot;NLE&quot;</span><span class="p">,</span>
            <span class="o">**</span><span class="n">hparams</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">inference</span><span class="o">.</span><span class="n">trainer</span><span class="o">.</span><span class="n">load_model</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">inference</span></div>
</div>

</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Sacha Guerrini
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2025, Sacha Guerrini.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>