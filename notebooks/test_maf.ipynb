{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked Autoregressive Flows (MAFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 14:01:47.195470: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-12 14:01:47.195558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-12 14:01:47.235657: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-12 14:01:50.034564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"0.33\"\n",
    "\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import haiku as hk\n",
    "import optax\n",
    "import sbibm\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "from importlib import reload\n",
    "from typing import Sequence, Callable\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "from normflow.utils import create_data_loader\n",
    "from normflow.train import TrainerModule, TrainState\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Masked Linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 14:02:02.784058: W external/xla/xla/service/gpu/nvptx_compiler.cc:698] The NVIDIA driver's CUDA version is 11.5 which is older than the ptxas CUDA version (11.8.89). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "from normflow.model import MaskedLinear\n",
    "\n",
    "model = MaskedLinear(3)\n",
    "input = jnp.arange(5)\n",
    "mask = jnp.zeros((5, 3))\n",
    "model.initialize_mask(mask)\n",
    "\n",
    "params = model.init(jax.random.PRNGKey(0), input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([0., 0., 0.], dtype=float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(params, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "mask = jnp.ones((5, 3))\n",
    "model.initialize_mask(mask)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 1.6449495 ,  0.90466896, -4.55038121], dtype=float64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(params, input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normflow.model import ConditionalMADE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConditionalMADE(3, [5, 5], n_cond=3, gaussian=True, random_order=True, seed=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.init(jax.random.PRNGKey(0), jnp.zeros(3), jnp.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = jnp.array([0.5, 0.5, 0.5])\n",
    "cond = jnp.array([1, 1, 1])\n",
    "result = model.apply(params, input, cond) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.1636737 ,  0.        , -0.02277961,  0.26304815,  0.        ,\n",
       "       -0.04986678], dtype=float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing MAF Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normflow.model import MAFLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf_layer = MAFLayer(3, 3, [5, 5], reverse=False, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = maf_layer.init(jax.random.PRNGKey(0), jnp.zeros(3), jnp.zeros(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 0.        , -0.06895558, -0.1840593 ,  0.        ,  0.29709058,\n",
       "         0.5259207 ],\n",
       "       [ 0.        , -0.06895558, -0.1840593 ,  0.        ,  0.29709058,\n",
       "         0.5259207 ],\n",
       "       [ 0.        , -0.06895558, -0.1840593 ,  0.        ,  0.29709058,\n",
       "         0.5259207 ]], dtype=float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maf_layer.apply(params, input, cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[1.        , 1.24014384, 1.5401949 ],\n",
       "        [1.        , 1.24014384, 1.5401949 ],\n",
       "        [1.        , 1.24014384, 1.5401949 ]], dtype=float64),\n",
       " Array([-0.82301127, -0.82301127, -0.82301127], dtype=float64))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = jnp.ones((3, 3))\n",
    "cond = jnp.ones((3, 3))\n",
    "maf_layer.apply(params, input, cond, method=\"forward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[-0.87181784, -0.13588471, -1.76559334],\n",
       "        [ 0.22557418, -1.32635791, -0.64412577],\n",
       "        [ 0.95800807, -0.03642215, -1.8372651 ]], dtype=float64),\n",
       " Array([-0.22556734, -0.28683553, -0.39244059], dtype=float64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "u = jax.random.normal(key, shape=(3, 3))\n",
    "maf_layer.apply(params, u, cond, method=\"backward\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing MAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normflow.model import ConditionalMAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "maf = ConditionalMAF(3, 3, 2, [5, 5], use_reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01088361  0.13817746 -0.10314687]\n",
      " [ 0.01088361  0.13817746 -0.10314687]\n",
      " [ 0.01088361  0.13817746 -0.10314687]] [[0.03759936 0.17010485 0.11047074]\n",
      " [0.03759936 0.17010485 0.11047074]\n",
      " [0.03759936 0.17010485 0.11047074]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]] [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "input = jnp.ones((3, 3))\n",
    "cond = jnp.zeros((3,3))\n",
    "train = True\n",
    "variables  = maf.init(jax.random.PRNGKey(0), input, cond, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'params': {'layer_list_0': {'ConditionalMADE_0': {'layers_0': {'Dense_0': {'kernel': Array([[-0.54132503, -0.13937119, -0.83233386, -0.19278507,  0.2364886 ],\n",
      "       [-0.39508113,  0.7051872 ,  0.18484904, -0.07446067,  0.27625823],\n",
      "       [ 0.30842176,  0.2557898 ,  0.32346186,  0.03034411, -0.09133991],\n",
      "       [ 0.45867676, -0.06275149, -0.38640818, -0.24083719,  0.23644099],\n",
      "       [ 0.11918586, -0.83387583,  0.36617702, -0.35819858,  0.4998809 ],\n",
      "       [-0.70595044,  0.17929627,  0.575624  ,  0.22423312,  0.83549535]],      dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}, 'layers_2': {'Dense_0': {'kernel': Array([[-7.70006955e-01,  4.56767827e-01,  8.51172924e-01,\n",
      "        -3.77410352e-01, -7.73304999e-02],\n",
      "       [-1.42954081e-01, -2.88688451e-01,  2.43010938e-01,\n",
      "         5.31215668e-01, -6.52666748e-01],\n",
      "       [-6.86863884e-02,  6.43747598e-02,  8.32371950e-01,\n",
      "        -9.15707409e-01,  1.73467901e-02],\n",
      "       [ 3.24441016e-01,  1.67332180e-02, -5.00603437e-01,\n",
      "         4.35714312e-02,  1.85305340e-04],\n",
      "       [-1.19220525e-01,  2.00174302e-01, -5.26747406e-01,\n",
      "         2.97233224e-01, -7.49860406e-01]], dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}, 'layers_4': {'Dense_0': {'kernel': Array([[-0.7195338 , -0.33609056,  0.4972284 , -0.7239414 , -0.89098626,\n",
      "        -0.32293856],\n",
      "       [-0.43889707, -0.49882704,  0.09870451,  0.00228664,  0.0068066 ,\n",
      "         0.5662538 ],\n",
      "       [ 0.52495575,  0.24006669,  0.19329321, -0.5828085 , -0.72338355,\n",
      "        -0.20906657],\n",
      "       [ 0.01388759,  0.04522325, -0.3698052 ,  0.41044423,  0.17078106,\n",
      "         0.37582335],\n",
      "       [-0.14705962, -0.5109196 , -0.28415376,  0.82402325, -0.22122835,\n",
      "        -0.04824551]], dtype=float32), 'bias': Array([0., 0., 0., 0., 0., 0.], dtype=float32)}}}}, 'BatchNorm_0': {'scale': Array([1., 1., 1.], dtype=float32), 'bias': Array([0., 0., 0.], dtype=float32)}, 'layer_list_1': {'ConditionalMADE_0': {'layers_0': {'Dense_0': {'kernel': Array([[ 0.45576534, -0.4442528 ,  0.14681076,  0.08390588,  0.04344136],\n",
      "       [ 0.37174734, -0.44754806, -0.3681241 ,  0.11661971, -0.5698095 ],\n",
      "       [ 0.44063264,  0.08522011,  0.18663459, -0.448576  ,  0.14052531],\n",
      "       [ 0.03576293, -0.0411165 ,  0.39522758,  0.7274959 , -0.26367837],\n",
      "       [ 0.498437  , -0.509552  ,  0.3826646 , -0.20403501, -0.5582577 ],\n",
      "       [-0.78336644,  0.1672124 ,  0.08330379, -0.5361868 ,  0.04924436]],      dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}, 'layers_2': {'Dense_0': {'kernel': Array([[-0.00477243, -0.88856673, -0.12548445, -0.7243121 , -0.63182247],\n",
      "       [-0.28953904, -0.658334  ,  0.0965037 ,  0.00320544, -0.24274014],\n",
      "       [-0.12299703, -0.24679434,  0.21936959,  0.18263319,  0.85198903],\n",
      "       [-0.0369938 ,  0.3553543 ,  0.3888549 ,  0.750519  , -0.720732  ],\n",
      "       [ 0.43147624,  0.18916972,  0.07704592,  0.18821795,  0.33970535]],      dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}, 'layers_4': {'Dense_0': {'kernel': Array([[-0.27966064, -0.6690207 , -0.38353387, -0.19811824, -0.57664514,\n",
      "        -0.21512677],\n",
      "       [-0.5992164 ,  0.2169489 , -0.19249067,  0.26502347, -0.00165294,\n",
      "        -0.07016777],\n",
      "       [-0.6169264 ,  0.05497755,  0.850185  ,  0.25598243,  0.4684359 ,\n",
      "        -0.02621563],\n",
      "       [-0.05809749, -0.31302682,  0.09765386,  0.16827215, -0.9487703 ,\n",
      "        -0.12684785],\n",
      "       [-0.6242996 , -0.16873665, -0.4374793 ,  0.19503437, -0.42088   ,\n",
      "         0.41899508]], dtype=float32), 'bias': Array([0., 0., 0., 0., 0., 0.], dtype=float32)}}}}, 'BatchNorm_1': {'scale': Array([1., 1., 1.], dtype=float32), 'bias': Array([0., 0., 0.], dtype=float32)}, 'layer_list_2': {'ConditionalMADE_0': {'layers_0': {'Dense_0': {'kernel': Array([[-0.02002497,  0.1759022 , -0.08115431,  0.80778134, -0.5893197 ],\n",
      "       [-0.69486904,  0.2912475 , -0.11698605,  0.87082416, -0.72401226],\n",
      "       [ 0.463541  , -0.26799226, -0.13136905, -0.37031028,  0.7955526 ],\n",
      "       [-0.00740531, -0.40433738,  0.32800683,  0.34074432, -0.372492  ],\n",
      "       [ 0.27918932,  0.05863331, -0.08265546, -0.04679032, -0.21373586],\n",
      "       [-0.566524  ,  0.06807457,  0.27676797,  0.6037619 ,  0.05653551]],      dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}, 'layers_2': {'Dense_0': {'kernel': Array([[ 0.8477249 , -0.32402214, -0.45280063, -0.31541407, -0.72559655],\n",
      "       [-0.8027281 , -0.7767449 , -0.5282918 ,  0.03627997,  0.2573603 ],\n",
      "       [ 0.04299265,  0.48904487,  0.39362782, -0.0785725 ,  0.28954667],\n",
      "       [ 0.6546203 ,  0.37840012,  0.15102553, -0.23902923,  0.4699228 ],\n",
      "       [ 0.29387355, -0.06787296,  0.28461722, -0.20070843,  0.9737754 ]],      dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}, 'layers_4': {'Dense_0': {'kernel': Array([[ 0.6974112 ,  0.18020344, -0.3831438 ,  0.62681156,  0.29315987,\n",
      "         0.08417888],\n",
      "       [-0.18770944,  0.43182698, -0.538337  ,  0.11389393, -0.56005096,\n",
      "        -0.6729011 ],\n",
      "       [ 0.3264652 ,  0.7815757 ,  0.23455362,  0.6859013 , -0.3274124 ,\n",
      "         0.26841512],\n",
      "       [-0.01840979,  0.6318198 , -0.00456057,  0.59204316, -0.36513102,\n",
      "         0.07773184],\n",
      "       [ 0.6877039 , -0.33361092,  0.41450545, -0.52083874,  0.4157322 ,\n",
      "         0.43167707]], dtype=float32), 'bias': Array([0., 0., 0., 0., 0., 0.], dtype=float32)}}}}, 'BatchNorm_2': {'scale': Array([1., 1., 1.], dtype=float32), 'bias': Array([0., 0., 0.], dtype=float32)}, 'layer_list_3': {'ConditionalMADE_0': {'layers_0': {'Dense_0': {'kernel': Array([[ 0.20646165, -0.09213886,  0.00464904, -0.04884596,  0.3109418 ],\n",
      "       [-0.52437836,  0.29739448, -0.43470094, -0.65030926,  0.18746242],\n",
      "       [-0.33028507, -0.56048113,  0.03487945,  0.3139859 ,  0.02059832],\n",
      "       [ 0.32635468,  0.10877906,  0.20399606, -0.25789523,  0.12432272],\n",
      "       [-0.8313594 , -0.32252827, -0.00801457,  0.49399656,  0.34057915],\n",
      "       [-0.5014648 ,  0.77599627,  0.2828527 , -0.30834943, -0.786202  ]],      dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}, 'layers_2': {'Dense_0': {'kernel': Array([[ 0.843217  ,  0.36362812, -0.9230142 ,  0.2843493 , -0.60159826],\n",
      "       [-0.15704241,  0.02597547,  0.6385368 , -0.24513519, -0.32431567],\n",
      "       [ 0.11833117,  0.1785108 , -0.4103153 ,  0.46550754,  0.64109105],\n",
      "       [ 0.8148118 ,  0.48546916, -0.01572995,  0.25505581,  0.19859205],\n",
      "       [ 0.6740928 ,  0.22759536, -0.37536418,  0.99939084,  0.03998914]],      dtype=float32), 'bias': Array([0., 0., 0., 0., 0.], dtype=float32)}}, 'layers_4': {'Dense_0': {'kernel': Array([[ 0.15335688, -0.4408376 ,  0.11177615,  0.19575866,  0.6574357 ,\n",
      "         0.08191365],\n",
      "       [ 0.44306743, -0.62834424, -0.2546027 ,  0.26228216, -0.77055466,\n",
      "         0.49228758],\n",
      "       [ 0.30858788, -0.3660837 ,  0.12720259,  0.8927072 , -0.9587762 ,\n",
      "         0.52357185],\n",
      "       [ 0.26137358, -0.4289102 ,  0.1271137 ,  0.24042125, -0.79021496,\n",
      "        -0.15588814],\n",
      "       [ 0.1413031 ,  0.34026238,  0.02565416,  0.56383336,  0.12177244,\n",
      "        -0.5701378 ]], dtype=float32), 'bias': Array([0., 0., 0., 0., 0., 0.], dtype=float32)}}}}, 'BatchNorm_3': {'scale': Array([1., 1., 1.], dtype=float32), 'bias': Array([0., 0., 0.], dtype=float32)}}, 'batch_stats': {'BatchNorm_0': {'mean': Array([0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1.], dtype=float32)}, 'BatchNorm_1': {'mean': Array([0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1.], dtype=float32)}, 'BatchNorm_2': {'mean': Array([0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1.], dtype=float32)}, 'BatchNorm_3': {'mean': Array([0., 0., 0.], dtype=float32), 'var': Array([1., 1., 1.], dtype=float32)}}}\n"
     ]
    }
   ],
   "source": [
    "print(variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.02698668]\n",
      " [ 0.          0.05558876 -0.07202658]\n",
      " [ 0.          0.11791446 -0.05776139]] [[ 0.          0.         -0.03875391]\n",
      " [ 0.          0.02406995  0.13435566]\n",
      " [ 0.          0.051057    0.23350679]]\n",
      "[[ 0.          0.          0.05229088]\n",
      " [ 0.          0.         -0.08914018]\n",
      " [ 0.          0.         -0.20133093]] [[ 0.          0.         -0.05729698]\n",
      " [ 0.          0.         -0.04575677]\n",
      " [ 0.          0.         -0.01489341]]\n"
     ]
    }
   ],
   "source": [
    "input = jnp.arange(9).reshape((3,3))\n",
    "(u, log_det_sum), batch_stats = maf.apply(variables, input, cond, train=False, mutable=['batch_stats'])\n",
    "print(u)\n",
    "print(log_det_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.        ]\n",
      " [ 0.          0.00760531 -0.05514541]\n",
      " [ 0.          0.01939811 -0.04503168]] [[0.         0.         0.        ]\n",
      " [0.         0.18610822 0.13248495]\n",
      " [0.         0.29525823 0.22329616]]\n",
      "[[ 0.          0.00818851  0.00144857]\n",
      " [ 0.          0.0001618  -0.00181604]\n",
      " [ 0.         -0.0095467   0.1087742 ]] [[ 0.          0.0239594   0.02237393]\n",
      " [ 0.          0.00044799  0.00110936]\n",
      " [ 0.         -0.02501798 -0.06018259]]\n",
      "[[ 0.          0.01144308  0.31136306]\n",
      " [ 0.         -0.00067886 -0.0035404 ]\n",
      " [ 0.         -0.00852165 -0.0849013 ]] [[ 0.         -0.02510622  0.31882266]\n",
      " [ 0.          0.00264183 -0.00135427]\n",
      " [ 0.          0.09041838 -0.00408985]]\n",
      "[[ 0.          0.03032454  0.04309258]\n",
      " [ 0.         -0.00381028  0.00294329]\n",
      " [ 0.         -0.05069178 -0.00840889]] [[ 0.          0.04179559  0.0529142 ]\n",
      " [ 0.         -0.00545692 -0.00035966]\n",
      " [ 0.         -0.0749981  -0.03772373]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array([-5.53876795, -3.08269445, -5.30628243], dtype=float64),\n",
       " {'batch_stats': {'BatchNorm_0': {'mean': Array([0.05465552, 0.04490945, 0.03      ], dtype=float64),\n",
       "    'var': Array([1.07157778, 1.07386572, 1.05000001], dtype=float64)},\n",
       "   'BatchNorm_1': {'mean': Array([-5.17602857e-04, -9.67037984e-05,  2.96059473e-18], dtype=float64),\n",
       "    'var': Array([0.99900728, 1.00013437, 1.        ], dtype=float64)},\n",
       "   'BatchNorm_2': {'mean': Array([-0.00163036,  0.00023545,  0.        ], dtype=float64),\n",
       "    'var': Array([1.00618501, 1.00052477, 0.9999999 ], dtype=float64)},\n",
       "   'BatchNorm_3': {'mean': Array([-3.16179404e-04, -1.64963604e-04, -7.40148683e-19], dtype=float64),\n",
       "    'var': Array([1.00054688, 1.00048037, 0.99999995], dtype=float64)}}})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maf.apply(variables, input, cond, train=True, mutable=['batch_stats'], method='log_prob')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-5.06370052, -2.83433179, -5.12859794], dtype=float64)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = jnp.zeros(u.shape[1])\n",
    "cov = jnp.eye(u.shape[1])\n",
    "\n",
    "jax.scipy.stats.multivariate_normal.logpdf(u, mean, cov) + log_det_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([5.06370052, 2.83433179, 5.12859794], dtype=float64)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.sum(0.5 * u**2, axis=1) + 0.5*u.shape[1]*jnp.log(2*jnp.pi) - log_det_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bernoulli_glm',\n",
       " 'gaussian_linear',\n",
       " 'gaussian_linear_uniform',\n",
       " 'gaussian_mixture',\n",
       " 'lotka_volterra',\n",
       " 'sir',\n",
       " 'slcp',\n",
       " 'two_moons',\n",
       " 'slcp_distractors',\n",
       " 'bernoulli_glm_raw']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sbibm.get_available_tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10\n"
     ]
    }
   ],
   "source": [
    "task = sbibm.get_task('gaussian_linear')\n",
    "prior = task.get_prior()\n",
    "simulator = task.get_simulator()\n",
    "reference_samples = jnp.array(task.get_reference_posterior_samples(num_observation=1))\n",
    "observation = jnp.array(task.get_observation(num_observation=1))\n",
    "truth = jnp.array(task.get_true_parameters(num_observation=1).flatten())\n",
    "\n",
    "dim = truth.shape[0]\n",
    "dim_cond = observation.shape[1]\n",
    "\n",
    "print(dim, dim_cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimulationDataset(data.Dataset):\n",
    "    def __init__(self, simulator, prior, num_samples):\n",
    "        super().__init__()\n",
    "        self.thetas = prior(num_samples=num_samples)\n",
    "        self.xs = simulator(self.thetas)\n",
    "        self.thetas, self.xs = np.array(self.thetas), np.array(self.xs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.thetas)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.thetas[index], self.xs[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/feynman/home/dap/lcs/sg276684/.conda/envs/jax_sbi/lib/python3.10/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_set = SimulationDataset(simulator, prior, 20000)\n",
    "val_set = SimulationDataset(simulator, prior, 2000)\n",
    "test_set = SimulationDataset(simulator, prior, 5000)\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loader(\n",
    "    train_set, val_set, test_set,\n",
    "    train = [True, False, False],\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural posterior estimation using MAFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from normflow.model import ConditionalMAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MAFTrainer(TrainerModule):\n",
    "    def __init__(self,\n",
    "                 n_data : int,\n",
    "                 n_cond : int,\n",
    "                 n_layers : int,\n",
    "                 hidden_dims : list[int],\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super().__init__(model_class=ConditionalMAF,\n",
    "                         model_hparams={\n",
    "                             'n_in': n_data,\n",
    "                             'n_cond': n_cond,\n",
    "                             'n_layers': n_layers,\n",
    "                             'hidden_dims': hidden_dims\n",
    "                         },\n",
    "                         \n",
    "                         **kwargs)\n",
    "        \n",
    "    def create_functions(self):\n",
    "        def loss_nll(params, batch, batch_stats, train):\n",
    "            thetas, xs = batch\n",
    "            output = self.model.apply(\n",
    "                {'params': params, 'batch_stats': batch_stats},\n",
    "                  thetas, xs, train,\n",
    "                  mutable=['batch_stats'], method='log_prob')[0]\n",
    "            return -jnp.mean(output)\n",
    "        \n",
    "        def train_step(state, batch):\n",
    "            loss_fn = lambda params: loss_nll(params, batch, state.batch_stats, train=True)\n",
    "            loss, grads = jax.value_and_grad(loss_fn)(state.params)\n",
    "            print(loss)\n",
    "            state = state.apply_gradients(grads=grads)\n",
    "            metrics = {'loss': loss}\n",
    "            return state, metrics\n",
    "        \n",
    "        def eval_step(state, batch):\n",
    "            loss = loss_nll(state.params, batch, train=False)\n",
    "            return {'loss': loss}\n",
    "        \n",
    "        return train_step, eval_step\n",
    "        \n",
    "    def print_tabulate(self, exmp_input):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping jitting due to debug=True\n",
      "[[-1.00118387e-02 -9.86540914e-02 -1.20266765e-01 ...  1.00235343e-02\n",
      "   7.18911514e-02 -9.19812173e-03]\n",
      " [ 2.89798789e-02 -3.12203821e-02 -6.44682422e-02 ... -1.49201378e-02\n",
      "  -1.25318123e-02  3.74837033e-02]\n",
      " [-6.20602369e-02 -7.94130415e-02 -2.70297267e-02 ... -1.22951381e-01\n",
      "  -4.81680185e-02 -1.01984674e-02]\n",
      " ...\n",
      " [-1.83903426e-02 -1.06767312e-01 -1.24860339e-01 ... -1.50371954e-01\n",
      "   7.59222209e-02 -3.31170447e-02]\n",
      " [-2.30744537e-02  4.91057709e-02 -1.21682100e-01 ... -1.14026472e-01\n",
      "  -1.05509378e-01 -1.33088529e-01]\n",
      " [ 1.87471174e-02  6.98024184e-02  4.36380506e-05 ...  9.46689472e-02\n",
      "   7.21517578e-02 -1.13044001e-01]] [[ 0.11145411 -0.0326547   0.08906975 ...  0.08474484 -0.21455601\n",
      "  -0.08674689]\n",
      " [ 0.0373889   0.00656105  0.07427783 ... -0.02988476 -0.02362293\n",
      "   0.03802176]\n",
      " [ 0.02483803 -0.09055373 -0.0110162  ... -0.03034341 -0.09489576\n",
      "  -0.21393755]\n",
      " ...\n",
      " [-0.00538978 -0.03140695  0.03292181 ... -0.01571316  0.15287612\n",
      "  -0.11603244]\n",
      " [-0.06187838 -0.04303556 -0.04125162 ... -0.08938298 -0.01253439\n",
      "  -0.12978275]\n",
      " [-0.066891    0.18834111 -0.07575632 ... -0.05359852  0.0791314\n",
      "   0.09394462]]\n",
      "[[ 0.13838868  0.06961868 -0.10614035 ... -0.03728648  0.0842998\n",
      "   0.29475296]\n",
      " [ 0.09522659 -0.03399732  0.0220781  ... -0.1577321   0.03760454\n",
      "   0.26739287]\n",
      " [-0.02717472  0.09208358  0.3627598  ... -0.10365653  0.04429164\n",
      "   0.05733041]\n",
      " ...\n",
      " [ 0.31576222 -0.25196138 -0.04247427 ... -0.6334086   0.22265546\n",
      "   0.24815328]\n",
      " [ 0.33389774  0.253386    0.3187447  ... -0.2774747  -0.02860325\n",
      "   0.19151029]\n",
      " [-0.15387188  0.29374212  0.40340987 ...  0.1551901  -0.06877548\n",
      "   0.01420234]] [[ 0.30487084 -0.17233472  0.23199284 ... -0.14752382 -0.45666805\n",
      "  -0.20084567]\n",
      " [ 0.08586633 -0.1099484   0.46636605 ... -0.03909494 -0.3103469\n",
      "   0.07593517]\n",
      " [ 0.0394608   0.27399924 -0.0911486  ...  0.38014886 -0.02360609\n",
      "  -0.08786684]\n",
      " ...\n",
      " [ 0.2968727  -0.13406733  0.31948122 ...  0.4104793  -0.18606292\n",
      "   0.17375149]\n",
      " [ 0.42138892 -0.15516616  0.1051416  ...  0.38154498 -0.3952875\n",
      "  -0.03412275]\n",
      " [ 0.14930981 -0.04798482 -0.18003273 ...  0.23401098 -0.22671752\n",
      "   0.05163864]]\n",
      "[[-0.3229569  -0.17797226 -0.25235787 ...  0.23867896  0.02918711\n",
      "   0.24827151]\n",
      " [ 0.00234571  0.03134454 -0.09144202 ...  0.02357426  0.03863146\n",
      "  -0.2143921 ]\n",
      " [-0.14823616 -0.01727354  0.27824798 ... -0.0083121  -0.04326764\n",
      "   0.02319919]\n",
      " ...\n",
      " [-0.28315353  0.05946654  0.11567003 ... -0.07940002 -0.2605708\n",
      "   0.02668313]\n",
      " [-0.15757428 -0.24155375  0.2199679  ...  0.10493793 -0.21613544\n",
      "  -0.0153624 ]\n",
      " [-0.130077   -0.11557837  0.14925724 ...  0.23910615  0.31065306\n",
      "   0.08365561]] [[ 0.5467777  -0.05420766  0.14846742 ...  0.00674244  0.26671886\n",
      "  -0.42147267]\n",
      " [ 0.23070662  0.30467755 -0.00146939 ... -0.06999738  0.05676168\n",
      "  -0.20549105]\n",
      " [-0.06472497 -0.17138287  0.08762281 ...  0.04202304  0.01687241\n",
      "  -0.08506423]\n",
      " ...\n",
      " [ 0.1030203   0.12189455  0.32203147 ...  0.20669243 -0.08382155\n",
      "  -0.3597852 ]\n",
      " [ 0.05085702 -0.10088     0.3465394  ... -0.02651137  0.05957482\n",
      "  -0.19468099]\n",
      " [-0.13532183  0.13681713 -0.12129741 ... -0.13298443  0.15182704\n",
      "   0.01505352]]\n",
      "[[ 0.32810152  0.16587156 -0.16105565 ... -0.30799213 -0.25925708\n",
      "  -0.10049859]\n",
      " [ 0.04470278  0.37156677 -0.4525731  ... -0.22492532 -0.15556079\n",
      "   0.03464841]\n",
      " [ 0.15818791  0.27987257  0.04558184 ...  0.11424268  0.12439863\n",
      "   0.24298556]\n",
      " ...\n",
      " [ 0.31778756  0.6535144  -0.7420381  ...  0.09466909  0.3659077\n",
      "   0.07040366]\n",
      " [ 0.25614467  0.41282237 -0.00715756 ... -0.05335055  0.2260434\n",
      "   0.05375472]\n",
      " [ 0.12106601  0.19840439  0.15645875 ... -0.1493908  -0.15093015\n",
      "   0.0576431 ]] [[-0.08414309 -0.13372537  0.03354115 ...  0.22402357 -0.1771435\n",
      "  -0.43124214]\n",
      " [-0.04839995 -0.02639825  0.18687417 ...  0.10826662 -0.07727105\n",
      "  -0.2144381 ]\n",
      " [ 0.12115958 -0.00852142 -0.008928   ...  0.08294705  0.05946532\n",
      "   0.17084779]\n",
      " ...\n",
      " [ 0.09137328  0.00610485  0.3237316  ...  0.31528684  0.26116487\n",
      "  -0.07601429]\n",
      " [ 0.40930453 -0.04681681  0.1704094  ...  0.08389541  0.0764164\n",
      "   0.20338039]\n",
      " [-0.03941485 -0.06249771 -0.12288605 ...  0.01217008  0.10220299\n",
      "   0.1516866 ]]\n",
      "[[-0.34684998 -0.10213501 -0.06776986 ...  0.15760027 -0.06870122\n",
      "  -0.31788495]\n",
      " [-0.12360103  0.23894943  0.01473178 ... -0.18873073 -0.00619099\n",
      "   0.24149567]\n",
      " [-0.1742974   0.06007251  0.00251315 ... -0.07463679  0.10523529\n",
      "   0.02467437]\n",
      " ...\n",
      " [-0.09508694  0.08844917  0.6760339  ... -0.20524353 -0.1928613\n",
      "  -0.36688977]\n",
      " [ 0.15033765 -0.18575947  0.41808677 ... -0.11693099 -0.17012103\n",
      "  -0.14818618]\n",
      " [ 0.15796244 -0.06838226 -0.05954647 ...  0.16229856 -0.05958845\n",
      "  -0.07677478]] [[-0.17157939 -0.05822256  0.4415509  ... -0.10302619 -0.18204775\n",
      "   0.01828262]\n",
      " [-0.24147725  0.01448592  0.31102598 ... -0.04574801  0.08878251\n",
      "  -0.01332331]\n",
      " [-0.309887    0.12123642 -0.17291768 ...  0.08790082 -0.09708793\n",
      "  -0.07838763]\n",
      " ...\n",
      " [-0.87513244 -0.338667   -0.1469961  ...  0.11714868  0.34795776\n",
      "  -0.47673553]\n",
      " [-0.6739546   0.06070573 -0.6410777  ...  0.15507212  0.0485796\n",
      "  -0.4966475 ]\n",
      " [ 0.07452081  0.35837197 -0.3844163  ...  0.16664925 -0.08027137\n",
      "  -0.03885263]]\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = '~/work/jax/notebooks/checkpoints/'\n",
    "\n",
    "trainer = MAFTrainer(\n",
    "    n_data=dim,\n",
    "    n_cond=dim_cond,\n",
    "    n_layers=5,\n",
    "    hidden_dims=[256, 256],\n",
    "    optimizer_hparams={'lr': 4e-3},\n",
    "    logger_params={'base_log_dir': CHECKPOINT_PATH},\n",
    "    exmp_input=next(iter(train_loader)),\n",
    "    check_val_every_epoch=5,\n",
    "    debug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7747a5ee5840f79a4cbc5555147b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9da60289cc04b3aabb5d8d274a15c62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/156 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.030375036673416\n",
      "14.288329537518027\n",
      "12.572063751075863\n",
      "10.899622312975996\n",
      "9.158712029306093\n",
      "7.440626426231322\n",
      "4.891054224387533\n",
      "1.9927893700698085\n",
      "-1.0046130691963706\n",
      "-5.165362747499537\n",
      "-8.858695906740671\n",
      "-14.280096933177143\n",
      "-21.69410505797896\n",
      "-25.840713513469623\n",
      "-34.2837195643158\n",
      "-42.10452730424233\n",
      "-51.88027938072168\n",
      "-61.2933893063613\n",
      "-71.68460121338987\n",
      "-94.45586840268797\n",
      "-104.57546598223388\n",
      "-114.92737895208889\n",
      "-136.21793655436056\n",
      "-157.5377456542054\n",
      "-168.01283366255078\n",
      "-185.25426945620367\n",
      "-212.95122518414968\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/jax/normflow/train.py:302\u001b[0m, in \u001b[0;36mTrainerModule.train_model\u001b[0;34m(self, train_loader, val_loader, test_loader, num_epochs)\u001b[0m\n\u001b[1;32m    300\u001b[0m best_eval_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 302\u001b[0m     train_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_metrics(train_metrics, step\u001b[38;5;241m=\u001b[39mepoch_idx)\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_training_epoch_end(epoch_idx)\n",
      "File \u001b[0;32m~/work/jax/normflow/train.py:347\u001b[0m, in \u001b[0;36mTrainerModule.train_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    345\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtracker(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m'\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, step_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m step_metrics:\n\u001b[1;32m    349\u001b[0m         metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain/\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m+\u001b[39mkey] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m step_metrics[key] \u001b[38;5;241m/\u001b[39m num_train_steps\n",
      "Cell \u001b[0;32mIn[22], line 30\u001b[0m, in \u001b[0;36mMAFTrainer.create_functions.<locals>.train_step\u001b[0;34m(state, batch)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(state, batch):\n\u001b[1;32m     29\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m params: loss_nll(params, batch, state\u001b[38;5;241m.\u001b[39mbatch_stats, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 30\u001b[0m     loss, grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss)\n\u001b[1;32m     32\u001b[0m     state \u001b[38;5;241m=\u001b[39m state\u001b[38;5;241m.\u001b[39mapply_gradients(grads\u001b[38;5;241m=\u001b[39mgrads)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/api.py:735\u001b[0m, in \u001b[0;36mvalue_and_grad.<locals>.value_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    733\u001b[0m   _check_input_dtype_grad(holomorphic, allow_int, leaf)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 735\u001b[0m   ans, vjp_py \u001b[38;5;241m=\u001b[39m \u001b[43m_vjp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_partial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdyn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    737\u001b[0m   ans, vjp_py, aux \u001b[38;5;241m=\u001b[39m _vjp(\n\u001b[1;32m    738\u001b[0m       f_partial, \u001b[38;5;241m*\u001b[39mdyn_args, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, reduce_axes\u001b[38;5;241m=\u001b[39mreduce_axes)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/api.py:2223\u001b[0m, in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[1;32m   2222\u001b[0m   flat_fun, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun_nokwargs(fun, in_tree)\n\u001b[0;32m-> 2223\u001b[0m   out_primal, out_vjp \u001b[38;5;241m=\u001b[39m \u001b[43mad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvjp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2224\u001b[0m \u001b[43m      \u001b[49m\u001b[43mflat_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprimals_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduce_axes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2225\u001b[0m   out_tree \u001b[38;5;241m=\u001b[39m out_tree()\n\u001b[1;32m   2226\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:142\u001b[0m, in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvjp\u001b[39m(traceable, primals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, reduce_axes\u001b[38;5;241m=\u001b[39m()):\n\u001b[1;32m    141\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_aux:\n\u001b[0;32m--> 142\u001b[0m     out_primals, pvals, jaxpr, consts \u001b[38;5;241m=\u001b[39m \u001b[43mlinearize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mprimals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     out_primals, pvals, jaxpr, consts, aux \u001b[38;5;241m=\u001b[39m linearize(traceable, \u001b[38;5;241m*\u001b[39mprimals, has_aux\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/interpreters/ad.py:131\u001b[0m, in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m _, in_tree \u001b[38;5;241m=\u001b[39m tree_flatten(((primals, primals), {}))\n\u001b[1;32m    130\u001b[0m jvpfun_flat, out_tree \u001b[38;5;241m=\u001b[39m flatten_fun(jvpfun, in_tree)\n\u001b[0;32m--> 131\u001b[0m jaxpr, out_pvals, consts \u001b[38;5;241m=\u001b[39m \u001b[43mpe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace_to_jaxpr_nounits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjvpfun_flat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_pvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m out_primals_pvals, out_tangents_pvals \u001b[38;5;241m=\u001b[39m tree_unflatten(out_tree(), out_pvals)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mall\u001b[39m(out_primal_pval\u001b[38;5;241m.\u001b[39mis_known() \u001b[38;5;28;01mfor\u001b[39;00m out_primal_pval \u001b[38;5;129;01min\u001b[39;00m out_primals_pvals)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/profiler.py:336\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    335\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/interpreters/partial_eval.py:774\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_nounits\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m core\u001b[38;5;241m.\u001b[39mnew_main(JaxprTrace, name_stack\u001b[38;5;241m=\u001b[39mcurrent_name_stack) \u001b[38;5;28;01mas\u001b[39;00m main:\n\u001b[1;32m    773\u001b[0m   fun \u001b[38;5;241m=\u001b[39m trace_to_subjaxpr_nounits(fun, main, instantiate)\n\u001b[0;32m--> 774\u001b[0m   jaxpr, (out_pvals, consts, env) \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpvals\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    775\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env\n\u001b[1;32m    776\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m main, fun, env\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/linear_util.py:191\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    194\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "Cell \u001b[0;32mIn[22], line 29\u001b[0m, in \u001b[0;36mMAFTrainer.create_functions.<locals>.train_step.<locals>.<lambda>\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(state, batch):\n\u001b[0;32m---> 29\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m params: \u001b[43mloss_nll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_stats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     loss, grads \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mvalue_and_grad(loss_fn)(state\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(loss)\n",
      "Cell \u001b[0;32mIn[22], line 22\u001b[0m, in \u001b[0;36mMAFTrainer.create_functions.<locals>.loss_nll\u001b[0;34m(params, batch, batch_stats, train)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_nll\u001b[39m(params, batch, batch_stats, train):\n\u001b[1;32m     21\u001b[0m     thetas, xs \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m---> 22\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparams\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_stats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_stats\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m          \u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m          \u001b[49m\u001b[43mmutable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbatch_stats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_prob\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mjnp\u001b[38;5;241m.\u001b[39mmean(output)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1911\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, variables, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1909\u001b[0m   method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m\n\u001b[1;32m   1910\u001b[0m method \u001b[38;5;241m=\u001b[39m _get_unbound_fn(method)\n\u001b[0;32m-> 1911\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1912\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1913\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1914\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmutable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmutable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapture_intermediates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapture_intermediates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1916\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrngs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrngs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/core/scope.py:1080\u001b[0m, in \u001b[0;36mapply.<locals>.wrapper\u001b[0;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1075\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mApplyScopeInvalidVariablesStructureError(variables)\n\u001b[1;32m   1077\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m bind(\n\u001b[1;32m   1078\u001b[0m     variables, rngs\u001b[38;5;241m=\u001b[39mrngs, mutable\u001b[38;5;241m=\u001b[39mmutable, flags\u001b[38;5;241m=\u001b[39mflags\n\u001b[1;32m   1079\u001b[0m )\u001b[38;5;241m.\u001b[39mtemporary() \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[0;32m-> 1080\u001b[0m   y \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mutable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   1082\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m y, root\u001b[38;5;241m.\u001b[39mmutable_variables()\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:2572\u001b[0m, in \u001b[0;36mapply.<locals>.scope_fn\u001b[0;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2570\u001b[0m _context\u001b[38;5;241m.\u001b[39mcapture_stack\u001b[38;5;241m.\u001b[39mappend(capture_intermediates)\n\u001b[1;32m   2571\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2572\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_deep_clone\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2573\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2574\u001b[0m   _context\u001b[38;5;241m.\u001b[39mcapture_stack\u001b[38;5;241m.\u001b[39mpop()\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/work/jax/normflow/model.py:454\u001b[0m, in \u001b[0;36mConditionalMAF.log_prob\u001b[0;34m(self, x, y, train)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, train : \u001b[38;5;28mbool\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 454\u001b[0m     u, log_det_sum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m multivariate_normal\u001b[38;5;241m.\u001b[39mlogpdf(u, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmean, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov) \u001b[38;5;241m+\u001b[39m log_det_sum\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/work/jax/normflow/model.py:440\u001b[0m, in \u001b[0;36mConditionalMAF.__call__\u001b[0;34m(self, x, y, train)\u001b[0m\n\u001b[1;32m    438\u001b[0m log_det_sum \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mzeros(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_list:\n\u001b[0;32m--> 440\u001b[0m     x, log_det \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     log_det_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m log_det\n\u001b[1;32m    442\u001b[0m     x \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mBatchNorm(use_running_average\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m train)(x)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/work/jax/normflow/model.py:369\u001b[0m, in \u001b[0;36mMAFLayer.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 369\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     mu, logp \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39msplit(out, \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    371\u001b[0m     u \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m-\u001b[39mmu)\u001b[38;5;241m*\u001b[39mjnp\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39mlogp)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/work/jax/normflow/model.py:401\u001b[0m, in \u001b[0;36mMAFLayer.__call__\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;129m@nn\u001b[39m\u001b[38;5;241m.\u001b[39mcompact\n\u001b[1;32m    390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    391\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    Forward pass of the model. Returns mean and variance of the gaussian conditionals.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m        Conditionning variable\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mConditionalMADE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_in\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhidden_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_cond\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_cond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1079\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1077\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39min_setup \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1079\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_compact_method:\n\u001b[1;32m   1082\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscope \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1367\u001b[0m, in \u001b[0;36mModule._try_setup\u001b[0;34m(self, shallow)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_submodules(field\u001b[38;5;241m.\u001b[39mname, \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, field\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1366\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m shallow:\n\u001b[0;32m-> 1367\u001b[0m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;66;03m# We run static checks abstractly once for setup before any transforms\u001b[39;00m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;66;03m# to detect name collisions and other python errors.\u001b[39;00m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state\u001b[38;5;241m.\u001b[39msetup_called \u001b[38;5;241m==\u001b[39m SetupState\u001b[38;5;241m.\u001b[39mNEW:\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/work/jax/normflow/model.py:275\u001b[0m, in \u001b[0;36mConditionalMADE.setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m layers\u001b[38;5;241m.\u001b[39mappend(MaskedLinear(dim_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    274\u001b[0m \u001b[38;5;66;03m#Create masks\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_masks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m#Create model\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m layers\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:584\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(args[\u001b[38;5;241m0\u001b[39m], Module):\n\u001b[1;32m    583\u001b[0m   \u001b[38;5;28mself\u001b[39m, args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m], args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 584\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_wrapped_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/flax/linen/module.py:1101\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_named_call:\n\u001b[1;32m   1100\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[38;5;28mself\u001b[39m, fun)):\n\u001b[0;32m-> 1101\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m   y \u001b[38;5;241m=\u001b[39m run_fun(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/work/jax/normflow/model.py:329\u001b[0m, in \u001b[0;36mConditionalMADE._create_masks\u001b[0;34m(self, mask_matrix, masks, layers)\u001b[0m\n\u001b[1;32m    327\u001b[0m     M[j, :] \u001b[38;5;241m=\u001b[39m (m[j] \u001b[38;5;241m<\u001b[39m m_next)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m#append matrix to mask list\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m mask_matrix\u001b[38;5;241m.\u001b[39mappend(\u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mM\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m#If the output is Gaussian, double the number of output (mu, sigma)\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;66;03m#Pairwise identical mask\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgaussian:\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:2171\u001b[0m, in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m   2167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m array(np\u001b[38;5;241m.\u001b[39masarray(view), dtype, copy, ndmin\u001b[38;5;241m=\u001b[39mndmin)\n\u001b[1;32m   2169\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected input type for array: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2171\u001b[0m out_array: Array \u001b[38;5;241m=\u001b[39m \u001b[43mlax_internal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_element_type\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweak_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndmin \u001b[38;5;241m>\u001b[39m ndim(out_array):\n\u001b[1;32m   2174\u001b[0m   out_array \u001b[38;5;241m=\u001b[39m lax\u001b[38;5;241m.\u001b[39mexpand_dims(out_array, \u001b[38;5;28mrange\u001b[39m(ndmin \u001b[38;5;241m-\u001b[39m ndim(out_array)))\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/lax/lax.py:558\u001b[0m, in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    556\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m type_cast(Array, operand)\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 558\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconvert_element_type_p\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mweak_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweak_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/core.py:444\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams):\n\u001b[1;32m    442\u001b[0m   \u001b[38;5;28;01massert\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m config\u001b[38;5;241m.\u001b[39menable_checks\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    443\u001b[0m           \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Tracer) \u001b[38;5;129;01mor\u001b[39;00m valid_jaxtype(arg) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)), args\n\u001b[0;32m--> 444\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind_with_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfind_top_trace\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/core.py:447\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbind_with_trace\u001b[39m(\u001b[38;5;28mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 447\u001b[0m   out \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess_primitive\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull_raise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    448\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(full_lower, out) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmultiple_results \u001b[38;5;28;01melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/core.py:935\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess_primitive\u001b[39m(\u001b[38;5;28mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 935\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprimitive\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimpl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtracers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/jax_sbi/lib/python3.10/site-packages/jax/_src/dispatch.py:87\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m     85\u001b[0m prev \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 87\u001b[0m   outs \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     89\u001b[0m   lib\u001b[38;5;241m.\u001b[39mjax_jit\u001b[38;5;241m.\u001b[39mswap_thread_local_state_disable_jit(prev)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = trainer.train_model(\n",
    "    train_loader, val_loader, test_loader=test_loader, num_epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07524141 -0.07098564  0.17007238  0.08692858  0.29280627 -0.04115588\n",
      "   0.15075064 -0.02949537  0.1490141  -0.05084229]] [[ 0.15241149  0.10620734  0.08029716  0.10488478 -0.07990019  0.00041012\n",
      "  -0.07772311  0.00674023 -0.07814594 -0.04987648]]\n",
      "[[-0.02206277  0.09522    -0.04736716  0.07974109 -0.07755156 -0.08398766\n",
      "   0.1114552  -0.12040117 -0.10938451 -0.03987793]] [[-0.01036251 -0.08120312 -0.09541447  0.00907566  0.17816219 -0.06956849\n",
      "  -0.04758688  0.20996812 -0.18043426  0.10445471]]\n",
      "[[-0.01837941  0.17893694 -0.0909169  -0.1332468   0.07550838 -0.02053736\n",
      "   0.19932503 -0.0938931   0.0019726  -0.06548415]] [[-0.09093031  0.00398158 -0.00109191  0.03440513 -0.01388351 -0.16902106\n",
      "   0.00610279  0.01593171 -0.0716279  -0.10272319]]\n",
      "[[ 0.00336884  0.15998812  0.03277644 -0.1464412   0.1217975   0.0729499\n",
      "   0.14743857 -0.04280444 -0.08431569 -0.06164679]] [[ 0.03932717  0.06553723 -0.0197266  -0.03094918 -0.11925836 -0.09791546\n",
      "  -0.0366854  -0.10694012  0.07500197  0.0080463 ]]\n",
      "[[-0.0863263   0.09493946 -0.00300369  0.0601727   0.07371997 -0.1004722\n",
      "  -0.04570564 -0.1526487  -0.06363444  0.03693976]] [[-0.0764989   0.01018968  0.01601632  0.1542283   0.21067409 -0.08131365\n",
      "  -0.01056207  0.09015556 -0.04205843 -0.12379467]]\n"
     ]
    }
   ],
   "source": [
    "thetas = prior(1)\n",
    "xs = simulator(thetas)\n",
    "thetas, xs = np.array(thetas), np.array(xs)\n",
    "\n",
    "variables = trainer.model.init(jax.random.PRNGKey(2), thetas, xs, train=True)\n",
    "params, batch_stats = variables['params'], variables['batch_stats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00  1.32476916e-02  1.55555629e-02 -3.38504077e-05\n",
      "   4.26109241e-02  1.52985554e-02  2.96781506e-02 -7.13740189e-02\n",
      "   3.15622623e-02 -2.63978398e-02]] [[ 0.         -0.0052086  -0.02075232 -0.01945965 -0.05676127 -0.01972099\n",
      "   0.07672182  0.06797306  0.03360789  0.02826634]]\n",
      "[[ 0.          0.00849273  0.07897229  0.01647291  0.02791221 -0.03515343\n",
      "   0.12023774 -0.08847063 -0.02740332  0.00918744]] [[ 0.          0.00990543  0.03039456 -0.03042982  0.0218426   0.00300301\n",
      "   0.04487568  0.0869316  -0.14102385  0.09506175]]\n",
      "[[ 0.          0.00861651  0.0130103  -0.00247722 -0.01296349  0.0492893\n",
      "  -0.04292993 -0.06506122 -0.04071329 -0.01473076]] [[ 0.          0.00960667  0.00641029 -0.02348373  0.0076126  -0.05419772\n",
      "  -0.00973769  0.00416638  0.00539697  0.00052486]]\n",
      "[[ 0.         -0.00376171 -0.0035278   0.0077631  -0.01911593 -0.01883528\n",
      "   0.00613932  0.02240236 -0.04934928 -0.0139843 ]] [[ 0.         -0.00406313 -0.02491564 -0.02696103  0.00435466 -0.01508785\n",
      "  -0.02797314 -0.06132292  0.05710475  0.00317921]]\n",
      "[[ 0.         -0.00510223  0.00504489 -0.00501713 -0.00147524 -0.14812862\n",
      "  -0.0318672  -0.01471667 -0.14049921  0.11408306]] [[ 0.         -0.01149653  0.0104802   0.02898073  0.01424568 -0.02952985\n",
      "   0.04653362  0.06565376  0.00655696 -0.0838741 ]]\n"
     ]
    }
   ],
   "source": [
    "u, log_det_sum = trainer.model.apply(variables, thetas, xs, train=False, mutable=['batch_stats'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10) (1,)\n"
     ]
    }
   ],
   "source": [
    "print(u.shape, log_det_sum.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjYAAAGdCAYAAAABhTmFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnoElEQVR4nO3df3DU9YH/8dfm10Y0WaDAJsQ10a9HJMeY0AAhaEFnoqHeKKidST3bQK7SkUaOsp07SD1goEraopaZkjPAFNFyJxROCxYOvAmIWqJIkJOfCSlCgmYDCMkKp4nuvr9/OKxuSSgbApu883zMfP7IZz+fT97v9x/sk93PbhzGGCMAAAALxER7AAAAAN2FsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgjbhoD6C7BINBffzxx0pKSpLD4Yj2cAAAwGUwxujTTz/V0KFDFRNz5a+3WBM2H3/8sTweT7SHAQAAuqCxsVE33njjFV/HmrBJSkqS9NXCJCcnR3k0AADgcvj9fnk8ntDz+JWyJmwuvP2UnJxM2AAA0Mt0120k3DwMAACsQdgAAABrEDYAAMAahA0AALAGYQMAAKxB2AAAAGsQNgAAwBqEDQAAsAZhAwAArEHYAAAAaxA2AADAGoQNAACwBmEDAACsQdgAAABrEDYAAMAahA0AALAGYQMAAKzRpbCpqKhQRkaGEhMTlZeXp127dl3y+JaWFpWWlio1NVVOp1PDhg3T5s2bQ4+Xl5dr9OjRSkpK0pAhQzR58mTV1tZ2ZWgAAKAPizhs1q5dK6/Xq/nz52vPnj3Kzs5WYWGhTp482eHx7e3tuueee3Ts2DGtX79etbW1WrFihdLS0kLH7NixQ6WlpXrnnXf0P//zP/riiy9077336vz5812fGQAA6HMcxhgTyQl5eXkaPXq0li5dKkkKBoPyeDyaMWOG5syZc9HxlZWVWrx4sQ4fPqz4+PjL+h2nTp3SkCFDtGPHDo0fP/6yzvH7/XK5XGptbVVycvLlTwgAAERNdz9/R/SKTXt7u2pqalRQUPD1BWJiVFBQoOrq6g7P2bhxo/Lz81VaWiq3260RI0Zo0aJFCgQCnf6e1tZWSdLAgQM7PaatrU1+vz9sAwAAfVtEYXP69GkFAgG53e6w/W63Wz6fr8Nzjh49qvXr1ysQCGjz5s2aO3eunn32WT311FMdHh8MBvXTn/5Ud9xxh0aMGNHpWMrLy+VyuUKbx+OJZCoAAMBCV/1TUcFgUEOGDNHy5cuVm5uroqIiPfnkk6qsrOzw+NLSUu3fv19r1qy55HXLysrU2toa2hobG6/G8AEAQC8SF8nBgwYNUmxsrJqbm8P2Nzc3KyUlpcNzUlNTFR8fr9jY2NC+4cOHy+fzqb29XQkJCaH9TzzxhP70pz/pzTff1I033njJsTidTjmdzkiGDwAALBfRKzYJCQnKzc1VVVVVaF8wGFRVVZXy8/M7POeOO+5QfX29gsFgaF9dXZ1SU1NDUWOM0RNPPKFXX31V27Zt080339yVuQAAgD4u4reivF6vVqxYoRdffFGHDh3S9OnTdf78eZWUlEiSiouLVVZWFjp++vTpOnPmjGbOnKm6ujpt2rRJixYtUmlpaeiY0tJSrV69Wv/5n/+ppKQk+Xw++Xw+ffbZZ90wRQAA0FdE9FaUJBUVFenUqVOaN2+efD6fcnJytGXLltANxQ0NDYqJ+bqXPB6Ptm7dqlmzZun2229XWlqaZs6cqdmzZ4eOef755yVJd911V9jveuGFFzR16tQuTAsAAPRFEX+PTU/F99gAAND7RPV7bAAAAHoywgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYo0thU1FRoYyMDCUmJiovL0+7du265PEtLS0qLS1VamqqnE6nhg0bps2bN4cef/PNN3X//fdr6NChcjgc+uMf/9iVYQEAgD4u4rBZu3atvF6v5s+frz179ig7O1uFhYU6efJkh8e3t7frnnvu0bFjx7R+/XrV1tZqxYoVSktLCx1z/vx5ZWdnq6KiouszAQAAfZ7DGGMiOSEvL0+jR4/W0qVLJUnBYFAej0czZszQnDlzLjq+srJSixcv1uHDhxUfH/+3B+Rw6NVXX9XkyZMjGZb8fr9cLpdaW1uVnJwc0bkAACA6uvv5O6JXbNrb21VTU6OCgoKvLxATo4KCAlVXV3d4zsaNG5Wfn6/S0lK53W6NGDFCixYtUiAQuKKBt7W1ye/3h20AAKBviyhsTp8+rUAgILfbHbbf7XbL5/N1eM7Ro0e1fv16BQIBbd68WXPnztWzzz6rp556quujllReXi6XyxXaPB7PFV0PAAD0flf9U1HBYFBDhgzR8uXLlZubq6KiIj355JOqrKy8ouuWlZWptbU1tDU2NnbTiAEAQG8VF8nBgwYNUmxsrJqbm8P2Nzc3KyUlpcNzUlNTFR8fr9jY2NC+4cOHy+fzqb29XQkJCV0YtuR0OuV0Ort0LgAAsFNEr9gkJCQoNzdXVVVVoX3BYFBVVVXKz8/v8Jw77rhD9fX1CgaDoX11dXVKTU3tctQAAAB0JOK3orxer1asWKEXX3xRhw4d0vTp03X+/HmVlJRIkoqLi1VWVhY6fvr06Tpz5oxmzpypuro6bdq0SYsWLVJpaWnomHPnzmnv3r3au3evJOnDDz/U3r171dDQcIXTAwAAfUlEb0VJUlFRkU6dOqV58+bJ5/MpJydHW7ZsCd1Q3NDQoJiYr3vJ4/Fo69atmjVrlm6//XalpaVp5syZmj17duiY3bt36+677w797PV6JUlTpkzRqlWrujo3AADQx0T8PTY9Fd9jAwBA7xPV77EBAADoyQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYI0uhU1FRYUyMjKUmJiovLw87dq165LHt7S0qLS0VKmpqXI6nRo2bJg2b958RdcEAAD4axGHzdq1a+X1ejV//nzt2bNH2dnZKiws1MmTJzs8vr29Xffcc4+OHTum9evXq7a2VitWrFBaWlqXrwkAANARhzHGRHJCXl6eRo8eraVLl0qSgsGgPB6PZsyYoTlz5lx0fGVlpRYvXqzDhw8rPj6+W67ZEb/fL5fLpdbWViUnJ0cyJQAAECXd/fwd0Ss27e3tqqmpUUFBwdcXiIlRQUGBqqurOzxn48aNys/PV2lpqdxut0aMGKFFixYpEAh0+ZqS1NbWJr/fH7YBAIC+LaKwOX36tAKBgNxud9h+t9stn8/X4TlHjx7V+vXrFQgEtHnzZs2dO1fPPvusnnrqqS5fU5LKy8vlcrlCm8fjiWQqAADAQlf9U1HBYFBDhgzR8uXLlZubq6KiIj355JOqrKy8ouuWlZWptbU1tDU2NnbTiAEAQG8VF8nBgwYNUmxsrJqbm8P2Nzc3KyUlpcNzUlNTFR8fr9jY2NC+4cOHy+fzqb29vUvXlCSn0ymn0xnJ8AEAgOUiesUmISFBubm5qqqqCu0LBoOqqqpSfn5+h+fccccdqq+vVzAYDO2rq6tTamqqEhISunRNAACAjkT8VpTX69WKFSv04osv6tChQ5o+fbrOnz+vkpISSVJxcbHKyspCx0+fPl1nzpzRzJkzVVdXp02bNmnRokUqLS297GsCAABcjojeipKkoqIinTp1SvPmzZPP51NOTo62bNkSuvm3oaFBMTFf95LH49HWrVs1a9Ys3X777UpLS9PMmTM1e/bsy74mAADA5Yj4e2x6Kr7HBgCA3ieq32MDAADQkxE2AADAGoQNAACwBmEDAACsQdgAAABrEDYAAMAahA0AALAGYQMAAKxB2AAAAGsQNgAAwBqEDQAAsAZhAwAArEHYAAAAaxA2AADAGoQNAACwBmEDAACsQdgAAABrEDYAAMAahA0AALAGYQMAAKxB2AAAAGsQNgAAwBqEDQAAsAZhAwAArEHYAAAAaxA2AADAGoQNAACwBmEDAACsQdgAAABrEDYAAMAahA0AALAGYQMAAKxB2AAAAGsQNgAAwBpx0R4AAFxKIGi068MzOvnp5xqSlKgxNw9UbIwj2sMC0EMRNgB6rC37m7TgtYNqav08tC/Vlaj592dp4ojUKI4MQE/FW1EAeqQt+5s0ffWesKiRJF/r55q+eo+27G+K0sgA9GSEDYAeJxA0WvDaQZkOHruwb8FrBxUIdnQEgL6MsAHQ4+z68MxFr9R8k5HU1Pq5dn145toNCkCvQNgA6HFOftp51HTlOAB9B2EDoMcZkpTYrccB6DsIGwA9zpibByrVlajOPtTt0Fefjhpz88BrOSwAvQBhA6DHiY1xaP79WZJ0Udxc+Hn+/Vl8nw2AixA2AHqkiSNS9fwPvq0UV/jbTSmuRD3/g2/zPTYAOsQX9AHosSaOSNU9WSl88zCAy0bYAOjRYmMcyv9/34r2MAD0El16K6qiokIZGRlKTExUXl6edu3a1emxq1atksPhCNsSE8NfWm5ubtbUqVM1dOhQ9evXTxMnTtSRI0e6MjQAANCHRRw2a9euldfr1fz587Vnzx5lZ2ersLBQJ0+e7PSc5ORkNTU1hbbjx4+HHjPGaPLkyTp69Kg2bNig999/X+np6SooKND58+e7NisAANAnRRw2zz33nKZNm6aSkhJlZWWpsrJS/fr108qVKzs9x+FwKCUlJbS53e7QY0eOHNE777yj559/XqNHj1ZmZqaef/55ffbZZ3r55Ze7NisAANAnRRQ27e3tqqmpUUFBwdcXiIlRQUGBqqurOz3v3LlzSk9Pl8fj0aRJk3TgwIHQY21tbZIU9vZUTEyMnE6n3n777U6v2dbWJr/fH7YBAIC+LaKwOX36tAKBQNgrLpLkdrvl8/k6PCczM1MrV67Uhg0btHr1agWDQY0bN04nTpyQJN1222266aabVFZWprNnz6q9vV2/+tWvdOLECTU1df7Xe8vLy+VyuUKbx+OJZCoAAMBCV/17bPLz81VcXKycnBxNmDBBr7zyigYPHqxly5ZJkuLj4/XKK6+orq5OAwcOVL9+/bR9+3Z997vfVUxM58MrKytTa2traGtsbLzaUwEAAD1cRB/3HjRokGJjY9Xc3By2v7m5WSkpKZd1jfj4eI0cOVL19fWhfbm5udq7d69aW1vV3t6uwYMHKy8vT6NGjer0Ok6nU06nM5LhAwAAy0X0ik1CQoJyc3NVVVUV2hcMBlVVVaX8/PzLukYgENC+ffuUmnrxt4a6XC4NHjxYR44c0e7duzVp0qRIhgcAAPq4iL+gz+v1asqUKRo1apTGjBmjJUuW6Pz58yopKZEkFRcXKy0tTeXl5ZKkhQsXauzYsbr11lvV0tKixYsX6/jx43rsscdC11y3bp0GDx6sm266Sfv27dPMmTM1efJk3Xvvvd00TQAA0BdEHDZFRUU6deqU5s2bJ5/Pp5ycHG3ZsiV0Q3FDQ0PYvTFnz57VtGnT5PP5NGDAAOXm5mrnzp3KysoKHdPU1CSv16vm5malpqaquLhYc+fO7YbpAQCAvsRhjDHRHkR38Pv9crlcam1tVXJycrSHAwAALkN3P3/z170BAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANboUNhUVFcrIyFBiYqLy8vK0a9euTo9dtWqVHA5H2JaYmBh2zLlz5/TEE0/oxhtv1HXXXaesrCxVVlZ2ZWgAAKAPi4v0hLVr18rr9aqyslJ5eXlasmSJCgsLVVtbqyFDhnR4TnJysmpra0M/OxyOsMe9Xq+2bdum1atXKyMjQ6+//rp+8pOfaOjQoXrggQciHSIAAOijIn7F5rnnntO0adNUUlISemWlX79+WrlyZafnOBwOpaSkhDa32x32+M6dOzVlyhTdddddysjI0I9//GNlZ2df8pUgAACAvxZR2LS3t6umpkYFBQVfXyAmRgUFBaquru70vHPnzik9PV0ej0eTJk3SgQMHwh4fN26cNm7cqI8++kjGGG3fvl11dXW69957I5wOAADoyyIKm9OnTysQCFz0iovb7ZbP5+vwnMzMTK1cuVIbNmzQ6tWrFQwGNW7cOJ04cSJ0zG9/+1tlZWXpxhtvVEJCgiZOnKiKigqNHz++07G0tbXJ7/eHbQAAoG+L+B6bSOXn5ys/Pz/087hx4zR8+HAtW7ZMv/jFLyR9FTbvvPOONm7cqPT0dL355psqLS3V0KFDw14d+qby8nItWLDgag8fAAD0IhGFzaBBgxQbG6vm5uaw/c3NzUpJSbmsa8THx2vkyJGqr6+XJH322Wf6+c9/rldffVX/8A//IEm6/fbbtXfvXj3zzDOdhk1ZWZm8Xm/oZ7/fL4/HE8l0AACAZSJ6KyohIUG5ubmqqqoK7QsGg6qqqgp7VeZSAoGA9u3bp9TUVEnSF198oS+++EIxMeFDiY2NVTAY7PQ6TqdTycnJYRsAAOjbIn4ryuv1asqUKRo1apTGjBmjJUuW6Pz58yopKZEkFRcXKy0tTeXl5ZKkhQsXauzYsbr11lvV0tKixYsX6/jx43rsscckffVR8AkTJuhf/uVfdN111yk9PV07duzQSy+9pOeee64bpwoAAGwXcdgUFRXp1KlTmjdvnnw+n3JycrRly5bQDcUNDQ1hr76cPXtW06ZNk8/n04ABA5Sbm6udO3cqKysrdMyaNWtUVlamRx99VGfOnFF6erqefvppPf74490wRQAA0Fc4jDEm2oPoDn6/Xy6XS62trbwtBQBAL9Hdz9/8rSgAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYo0thU1FRoYyMDCUmJiovL0+7du3q9NhVq1bJ4XCEbYmJiWHH/PXjF7bFixd3ZXgAAKCPijhs1q5dK6/Xq/nz52vPnj3Kzs5WYWGhTp482ek5ycnJampqCm3Hjx8Pe/ybjzU1NWnlypVyOBx6+OGHI58RAADosyIOm+eee07Tpk1TSUmJsrKyVFlZqX79+mnlypWdnuNwOJSSkhLa3G532OPffCwlJUUbNmzQ3XffrVtuuSXyGQEAgD4rorBpb29XTU2NCgoKvr5ATIwKCgpUXV3d6Xnnzp1Tenq6PB6PJk2apAMHDnR6bHNzszZt2qQf/ehHlxxLW1ub/H5/2AYAAPq2iMLm9OnTCgQCF73i4na75fP5OjwnMzNTK1eu1IYNG7R69WoFg0GNGzdOJ06c6PD4F198UUlJSXrooYcuOZby8nK5XK7Q5vF4IpkKAACw0FX/VFR+fr6Ki4uVk5OjCRMm6JVXXtHgwYO1bNmyDo9fuXKlHn300YtuMP5rZWVlam1tDW2NjY1XY/gAAKAXiYvk4EGDBik2NlbNzc1h+5ubm5WSknJZ14iPj9fIkSNVX19/0WNvvfWWamtrtXbt2r95HafTKafTeXkDBwAAfUJEr9gkJCQoNzdXVVVVoX3BYFBVVVXKz8+/rGsEAgHt27dPqampFz32u9/9Trm5ucrOzo5kWAAAAJIifMVGkrxer6ZMmaJRo0ZpzJgxWrJkic6fP6+SkhJJUnFxsdLS0lReXi5JWrhwocaOHatbb71VLS0tWrx4sY4fP67HHnss7Lp+v1/r1q3Ts88+2w3TAgAAfVHEYVNUVKRTp05p3rx58vl8ysnJ0ZYtW0I3FDc0NCgm5usXgs6ePatp06bJ5/NpwIABys3N1c6dO5WVlRV23TVr1sgYo0ceeeQKpwQAAPoqhzHGRHsQ3cHv98vlcqm1tVXJycnRHg4AALgM3f38zd+KAgAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDUIGwAAYA3CBgAAWIOwAQAA1iBsAACANQgbAABgDcIGAABYg7ABAADWIGwAAIA1CBsAAGANwgYAAFiDsAEAANYgbAAAgDW6FDYVFRXKyMhQYmKi8vLytGvXrk6PXbVqlRwOR9iWmJh40XGHDh3SAw88IJfLpeuvv16jR49WQ0NDV4YHAAD6qIjDZu3atfJ6vZo/f7727Nmj7OxsFRYW6uTJk52ek5ycrKamptB2/PjxsMf/8pe/6M4779Rtt92mN954Qx988IHmzp3bYQABAAB0xmGMMZGckJeXp9GjR2vp0qWSpGAwKI/HoxkzZmjOnDkXHb9q1Sr99Kc/VUtLS6fX/P73v6/4+Hj9/ve/j2z03+D3++VyudTa2qrk5OQuXwcAAFw73f38HdErNu3t7aqpqVFBQcHXF4iJUUFBgaqrqzs979y5c0pPT5fH49GkSZN04MCB0GPBYFCbNm3SsGHDVFhYqCFDhigvL09//OMfLzmWtrY2+f3+sA0AAPRtEYXN6dOnFQgE5Ha7w/a73W75fL4Oz8nMzNTKlSu1YcMGrV69WsFgUOPGjdOJEyckSSdPntS5c+f0y1/+UhMnTtTrr7+uBx98UA899JB27NjR6VjKy8vlcrlCm8fjiWQqAADAQnFX+xfk5+crPz8/9PO4ceM0fPhwLVu2TL/4xS8UDAYlSZMmTdKsWbMkSTk5Odq5c6cqKys1YcKEDq9bVlYmr9cb+tnv9xM3AAD0cRGFzaBBgxQbG6vm5uaw/c3NzUpJSbmsa8THx2vkyJGqr68PXTMuLk5ZWVlhxw0fPlxvv/12p9dxOp1yOp2RDB8AAFguorBJSEhQbm6uqqqqNHnyZElf3SNTVVWlJ5544rKuEQgEtG/fPt13332ha44ePVq1tbVhx9XV1Sk9Pf2yx3bhHmjutQEAoPe48Lwd4WeZOmcitGbNGuN0Os2qVavMwYMHzY9//GPTv39/4/P5jDHG/PCHPzRz5swJHb9gwQKzdetW85e//MXU1NSY73//+yYxMdEcOHAgdMwrr7xi4uPjzfLly82RI0fMb3/7WxMbG2veeuutyx5XY2OjkcTGxsbGxsbWC7fGxsZIk6RDEd9jU1RUpFOnTmnevHny+XzKycnRli1bQjcUNzQ0KCbm63uSz549q2nTpsnn82nAgAHKzc3Vzp07w956evDBB1VZWany8nL98z//szIzM/Vf//VfuvPOOy97XEOHDlVjY6OSkpLkcDgimtOF+3MaGxv5qPg1wppfe6z5tceaX3us+bV3pWtujNGnn36qoUOHdst4Iv4eGxvxHTjXHmt+7bHm1x5rfu2x5tdeT1tz/lYUAACwBmEDAACsQdjoq4+Oz58/n4+PX0Os+bXHml97rPm1x5pfez1tzbnHBgAAWINXbAAAgDUIGwAAYA3CBgAAWIOwAQAA1rAybM6cOaNHH31UycnJ6t+/v370ox/p3Llzlzxn+fLluuuuu5ScnCyHw6GWlpaIr/vGG29o0qRJSk1N1fXXX6+cnBz9x3/8R3dPr0eK1ppL0gcffKDvfOc7SkxMlMfj0a9//evunFqP1ZU1//zzz1VaWqpvfetbuuGGG/Twww9f9Edtq6qqNG7cOCUlJSklJUWzZ8/Wl19+GXbM1q1bNXbsWCUlJWnw4MF6+OGHdezYse6eYo8TzTU3xuiZZ57RsGHD5HQ6lZaWpqeffrrb59jTRHPNL6ivr1dSUpL69+/fXdPq0aK15t32HNotf5ihh5k4caLJzs4277zzjnnrrbfMrbfeah555JFLnvOb3/zGlJeXm/LyciPJnD17NuLrPv300+bf/u3fzJ///GdTX19vlixZYmJiYsxrr73W3VPscaK15q2trcbtdptHH33U7N+/37z88svmuuuuM8uWLevuKfY4XVnzxx9/3Hg8HlNVVWV2795txo4da8aNGxd6fO/evSYhIcEsWLDAHDlyxLzxxhvmtttuMz/72c9Cxxw9etQ4nU5TVlZm6uvrTU1NjRk/frwZOXLkVZtrTxGtNTfGmBkzZpjMzEyzYcMGc/ToUbN7927z+uuvX5V59iTRXHNjjGlvbzejRo0y3/3ud43L5eru6fVI0Vrz7noOtS5sDh48aCSZ9957L7Tvv//7v43D4TAfffTR3zx/+/btHT7JdvW69913nykpKYl8Ir1INNf83//9382AAQNMW1tb6JjZs2ebzMzMK5xVz9aVNW9paTHx8fFm3bp1oX2HDh0ykkx1dbUxxpiysjIzatSosPM2btxoEhMTjd/vN8YYs27dOhMXF2cCgUDYMQ6Hw7S3t3fbHHuaaK75wYMHTVxcnDl8+HB3T6tHi+aaX/Cv//qv5gc/+IF54YUX+kTY9IQ1/6auPIda91ZUdXW1+vfvr1GjRoX2FRQUKCYmRu++++41v25ra6sGDhzY5d/bG0RzzaurqzV+/HglJCSEjiksLFRtba3Onj3b5d/d03VlzWtqavTFF1+ooKAgtO+2227TTTfdpOrqaklSW1ubEhMTw8677rrr9Pnnn6umpkaSlJubq5iYGL3wwgsKBAJqbW3V73//exUUFCg+Pr67p9pjRHPNX3vtNd1yyy3605/+pJtvvlkZGRl67LHHdObMme6eZo8SzTWXpG3btmndunWqqKjozmn1aNFe87/WledQ68LG5/NpyJAhYfvi4uI0cOBA+Xy+a3rdP/zhD3rvvfdUUlLS5d/bG0RzzX0+X+gvy19w4ecr+d09XVfW3OfzKSEh4aL7BNxud+icwsJC7dy5Uy+//LICgYA++ugjLVy4UJLU1NQkSbr55pv1+uuv6+c//7mcTqf69++vEydO6A9/+EM3z7JnieaaHz16VMePH9e6dev00ksvadWqVaqpqdH3vve9bp5lzxLNNf/kk080depUrVq1qkf8YcdrJZpr/te6+hzaa8Jmzpw5cjgcl9wOHz4c7WGGbN++XSUlJVqxYoX+/u//PtrD6ZLetuY2iPaa33vvvVq8eLEef/xxOZ1ODRs2TPfdd58kKSbmq38ufD6fpk2bpilTpui9997Tjh07lJCQoO9973syvfCLzHvDmgeDQbW1temll17Sd77zHd1111363e9+p+3bt6u2tvaqje1q6Q1rPm3aNP3jP/6jxo8ff9XGcS31hjX/pit5Do3rlhFfAz/72c80derUSx5zyy23KCUlRSdPngzb/+WXX+rMmTNKSUnp8u+P5Lo7duzQ/fffr9/85jcqLi7u8u+Mtt6w5ikpKRfdeX/h5yv53dFyNdc8JSVF7e3tamlpCfufVXNzc9g5Xq9Xs2bNUlNTkwYMGKBjx46prKxMt9xyiySpoqJCLpcr7NNnq1evlsfj0bvvvquxY8dGOOvo6g1rnpqaqri4OA0bNix0zvDhwyVJDQ0NyszMjGTKUdcb1nzbtm3auHGjnnnmGUlffSotGAwqLi5Oy5cv1z/90z91YebR0xvW/IIrfg6N6I6cXuDCjU+7d+8O7du6dWu33cj6t667fft2c/3115ulS5de+WR6iWiu+YWbh79502pZWVmfuXk4kjW/cIPf+vXrQ/sOHz4cdoNfR+bOnWs8Ho/58ssvjTHGeL1eM2bMmLBjPv74YyPJ/PnPf76SafVo0VzzrVu3Gkmmvr4+dMzevXuNJFNbW3ulU+uxornmBw8eNPv27QttTz31lElKSjL79u0zZ86c6aYZ9jzRXHNjuuc51LqwMearj6qNHDnSvPvuu+btt982f/d3fxf2UbUTJ06YzMxM8+6774b2NTU1mffff9+sWLHCSDJvvvmmef/9980nn3xy2dfdtm2b6devnykrKzNNTU2h7ZvXsFW01rylpcW43W7zwx/+0Ozfv9+sWbPG9OvXr8983DvSNX/88cfNTTfdZLZt22Z2795t8vPzTX5+fth1f/3rX5sPPvjA7N+/3yxcuNDEx8ebV199NfR4VVWVcTgcZsGCBaaurs7U1NSYwsJCk56ebv7v//7vqs87mqK15oFAwHz7298248ePN3v27DG7d+82eXl55p577rnqc462aK35X+srn4oyJnpr3l3PoVaGzSeffGIeeeQRc8MNN5jk5GRTUlJiPv3009DjH374oZFktm/fHto3f/58I+mi7YUXXrjs606ZMqXDa0yYMOEazDq6orXmxhjzv//7v+bOO+80TqfTpKWlmV/+8pdXe7o9QlfW/LPPPjM/+clPzIABA0y/fv3Mgw8+aJqamsKue/fddxuXy2USExNNXl6e2bx580W/++WXXzYjR440119/vRk8eLB54IEHzKFDh67aXHuKaK75Rx99ZB566CFzww03GLfbbaZOndon/tMUzTX/pr4UNtFa8+56DnUY0wvv9gMAAOhAr/lUFAAAwN9C2AAAAGsQNgAAwBqEDQAAsAZhAwAArEHYAAAAaxA2AADAGoQNAACwBmEDAACsQdgAAABrEDYAAMAahA0AALDG/wcQc4wuxEVrMwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.scatter(u[:,0], u[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
